<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos6 如何安装epel库]]></title>
    <url>%2F2018%2F09%2F04%2F2286277265%2F</url>
    <content type="text"><![CDATA[由于Centos6 系统有些年头了，所以安装epel库会出现各种问题先 通过命令来安装 yum install -y epel-release, 安装好了后，执行命令yum makecache，会发现无法连接到epel的源会显示如下错误：12345http://download.fedoraproject.org/pub/epel/6/x86_64/repodata/f3a638252f36722fa11f813216013305a6e8a95516f8919dc34fb7c8d9f39958-other.sqlite.bz2: [Errno 14] problem making ssl connectionTrying other mirror.Error: failure: repodata/f3a638252f36722fa11f813216013305a6e8a95516f8919dc34fb7c8d9f39958-other.sqlite.bz2 from epel: [Errno 256] No more mirrors to try.这是因为官方的ssl证书已经更新了，需要进行ca证书认证更新。但是由于epel源连接不上，导致yum安装命令无法使用，需要先卸载1yum erase epel-release再执行下面的命令，进行安装。所以正确的安装姿势如下：12345678#更新证书文件yum -y update ca-certificates# 安装epel库yum install -y epel-release#清空缓存yum clean all#生成本地缓存yum makecache安装完成后，可能有些同学还是连接不上mirror站点，报其他问题，这个时候，可以修改epel源的配置文件：把mirror注释掉，使用baseurl。这相当于不从镜像源去请求，直接使用fedora的官方源。还是推荐使用mirrorlist的，因为它可以给你调整最快的响应速度的源库1vim /etc/yum.repos.d/epel.repo本文地址： https://leaf0s.fun/2018/09/04/2286277265/]]></content>
      <categories>
        <category>技术实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[告别失控学习笔记]]></title>
    <url>%2F2018%2F08%2F20%2F1467955973%2F</url>
    <content type="text"><![CDATA[告别失控学习笔记人月神话里很好总结了程序设计充满乐趣的原因第一，是纯粹的创造的愉悦第二，是做出对其他人有用的东西而带来快乐第三，是设计组装谜题一样环环相扣的复杂部件，并观看它巧妙地运转而产生的吸引力第四，是持续学习的乐趣，这来源于任务的无重复特性第五，工作的对象是可以自由驾驭的代码，令人开心。程序员像诗人一样，操作的是雨纯粹思维事物只差一点点的代码尽管可以对程序员进行分类，但成功管理他们的关键却是要认识到他们是独立的个体。程序员之间的差异很大，你必须努力地让每个人的长处都得到发挥，同时尽力提高或者至少抵消每个人的短板。这条原则适用于任何领域的管理，不过在管理程序员时尤为重要。几乎在所有的软件中，程序的实际有形结果（即打印的报告、输出的数据甚至用户界面）雨实际程序的完成状态都是不成正比的。伊格尔森定律（Eagleson‘s Law）：自己写的代码如果有半年时间没有看过，就跟别人写的代码没啥区别。&quot;匠师&quot;这个比喻比其他称谓更适合我们所说的那种“杰出的程序员”如果程序员的动力主要来源于时间计划表、管理层压力或金钱，那他通常不会是一名杰出的程序员。对大多数杰出的程序员来说，动力事实上来源于更高的要求：在世界上产生影响，并且做出人们实际使用的程序或产品。杰出的程序员希望并且需要为具有世界影响的项目工作，他们希望能够感受到自己的工作是有意义的，哪怕只在某个很小的方面有意义。杰出的程序员偏爱能够满足他们更高要求的公司和项目，他们非常在意自己所做的事情，常常为了想要的结果而超限度地工作。管理程序员很像是在放牧一群猫——这句话常被引述，它揭示了高效、成功的程序设计经理难当的本质原因。猫的自由主义、个人主义色彩浓厚，而且狡猾、贪玩、好奇、独立。程序员也一样。对许多职业来说，报酬是主要的动力源泉；但对程序员来说，工作本身和工作环境的重要性要比报酬高很多。程序设计工作通常有下面4种类型：客户端程序员服务器程序员数据库程序员Web开发人员及其他脚本编写者一般情况下，建议不同类型的工作任务安排不同的程序员，不要指望哪个程序员能够同时兼任多种类型的工作。从技术知识、实践经验和程序员的专长角度去考虑也是很重要的，按这样的思路可以把程序员分类为：系统工程师/架构师系统程序员应用程序员非真正意义上的程序员如何有效判断沟通难度的方法：沟通的效果，在国内，是距离平方的倒数，跨越了国界，就是距离的立方的倒数距离越远（楼下、相邻的楼中、）在工程师和程序员中，代系差异是一直存在的，而今这些差异已经对职场产生显著的影响。当前，团队的成功必须依赖三代程序员的通力协作，而这三代人的价值观、想法和驱动力都不同。程序员的个性特点：左脑型的人与右脑型的人夜晚型的人与白天型的人 （沟通是个问题）“牧童” 与 “农民”。只能当“牧童”的程序员通常都不会在企业待太久，要么是你对他们总是自顾自地向前冲感到厌烦而辞退他们，要么是他们对长期受限制感到厌烦而主动辞职。英雄，英雄指的是需要超人的努力才能完成的任务，并最终取得成功的人。管理英雄的挑战是“如果你总是期望他们付出超人的努力，很容易就毁了他们。内向的人。在会议上让他们发言时，当他们分享自己的意见或见解时，要给予正面的支持，这样可以逐步帮助他们建立自信——自己对团队是有贡献。愤世嫉俗的人。尽量避免雇佣心存极大愤懑的人。奇葩，遵循“不招收奇葩”的法则。成功的招聘能让其他环节的工作更容易。最糟糕的招聘可能会给团队带来长达数月的诅咒，破坏你的领导形象，引起纷争和冲突，延迟或耽搁产品交付的日期，并以这样活那样的方式打消团队甚至整个组织的士气与动力。一流人才招聘一流人才，二流人才招聘三流人才。——Steve Jobs虽然分布式开发可行，但是分布式团队的效率无法和集中团队的相比。——Mike Cohn别把招聘看成是一系列一次性的挑战，要看成是持续的人际关系营建过程，这样，你就能在短期内给自己的人脉增值，并从长期上给招聘事业增值。你应当一致持续招聘。大学学历不会给我留下深刻的印象，缺少学校经历也不会吓到我。当一个人离开学校的时间足够长之后，学位就基本没有意义了。经验才是最重要的。通过简历写下如下问题：在这次成就中你扮演了什么角色这个工程中你做了哪个一部分为什么你在这家公司工作的时间这么短对公司来说，这个工作的效果如何实现这个技术最难的一面是什么这个工程中，你使用了哪些技术和工具你是使用什么语言编写这个工程的这个工程中你解决的最大挑战是什么你是如何学会这个新技能的招聘的简单经验法则：一个程序员，会的程序设计语言越多，就越优秀。另一方面，危险信号一般如下：候选人面试迟到；在面试中接电话；从来不尝试进行眼神交流；对之前的公司和经理表现出尖锐的批评；来的时候对你的公司或产品一无所知；不能解释之前工作中的一个设计；对你的工作没有表现出丝毫兴趣；没有分享出任何你可以从从中学习的知识；没有在面试后跟进发一个感谢电子邮件或留言。成功地管理程序员最重要、最关键的因素，是获取你管理的下属和同僚的技术尊重。如果没有获得技术尊重，那么你的每一次管理行动，都会遇到主动或被动的阻碍。正是由于这个原因，那些不懂得程序员（也就是说，没有在其职业生涯的某个时期做过程序员）的经理，才会觉得有效地管理程序员是极其困难的。这一点，在很多技术性的领域都有类似的情形，但在程序员的世界中则表现得尤为突出。要获得技术尊重，关键因素包括：理解计算机程序设计的艺术用户良好的过往履历做出值得称道的技术贡献追逐技术潮流的最前沿成为一个技术或者职业组织的活跃成员展现出强大的个人价值技术尊重的这些不可分割的组成元素，解释了为何从公司或组织外招聘程序设计经理，想让他们进行高效的管理是一件困难的事情。你考虑引入的管理程序设计团队的候选人，必须得拥有一系列“信任证明”（也就是在软件开发行业中有良好的、被证明的履历），才能使得团队对他产生尊重感。获得技术尊重的其他方法包括：获得高阶的技术学历；获得职业认证；撰写技术论文；创建开源、商用或者共享软件；申请专利；写书；创建自己的网站；开公司创业；创建自己的博客；在一个技术社区（如 Slashdot）中成为一名“众所周知”的贡献者；发明一个算法（如Page Rank算法、Warnock算法）；构造一个定律（如摩尔定律）；等等引导：身为经理，在目标没有达到时，要能够发现阻碍并尽可能地除掉它们。一个优秀的经理能够做得更好。他们能提前发现阻碍，并在它们实际导致目标无法实现之前就移除掉。而杰出的经理则能让这个过程看起来很容易。——Tony Bowden保护：保护你的团队成员，免受组织中每日泛滥不绝的各种问题、争议和“机会”的干扰。还要让你的成员知道你为了保护他们做出了贡献绩效评估为员工设立清晰的目标，可以产生明确的绩效评估方法，而你在向上司或者公司其他人沟通汇报时就可以更加清晰。给予更多的正面评价，而不是负面评价——Robert Sutton我的工作不是对人们宽容，我的工作是让他们变得更好——Steve Jobs知道何时削减损失。管理人员需要对组织和他们的同事负责，不应当容忍那些在重要的工作中表现得很差的个人。团队成员之间相隔越远，沟通应越证书越明确——Ted Young虚拟团队可以成功，但必须先解决额外的沟通开销以保证团队高效。电子邮件和即时通讯能够改善远程工作遇到的挑战，却不能完全消除它们。有时候，因为人可能误认为电子邮件与即时通讯就已经等价于沟通了，而实际上往往并不是这样，甚至会导致问题恶化。确保管理成功的关键，是确保获得并维护员工对你的技术尊重，聘请杰出的程序员并根据他们独特的个人情况进行管理，协助他们，保护他们，经常提供良好的反馈并作为正式绩效审查的一部分，并确保他们组成的团队能适应当前的任务和员工组成。写文档就像过性生活：如果做得好，那就非常非常好；如果做得不好，那也总比没有好。——Dick Brandon我认为一个小时的代码阅读抵得上两周的质量测试。它是消除错误的一种真正有效的方法。我现在觉得，代码阅读应该贯穿项目的整个生命周期。习惯成自然。没有记录的会议，相当于没有开过的会议。通过代码的行数来衡量软件生产力，就好比通过重量来衡量飞机的进步。——Bill Gates代码量与程序的完成状态、程序的质量或对用户的最终价值之间不存在可靠的关系学习新的工具或技术实际上会在最初降低程序员的生产力和产品的质量。只有在克服了这一学习曲线之后，你才能获得最终的收益。——Robert L. Glass具有做事的时候，架构师要少一些，砖瓦匠要多一些。——Colleen C. Barrett得到优秀的运动员容易，让他们配合起来难——Casey Stenge大多数人都真的希望能把工作做好。如果他们做得不好，通常是管理方面出了问题。——M. W. Mantle那些工作做得不好的人，通常是遇到了以下阻碍：缺乏设备、缺乏明确的方向，或者是其他一些问题或障碍，而优秀的管理者能够解决这些问题或障碍。我发现只要条件允许，几乎所有的程序员都希望超越预期。与我们通常所相信的观点相反，最美好的时刻并非是那些被动的、接受性的、放松的时刻——尽管它们是我们通过努力获得的，我们很享受。最美好的时刻通常是一个人在自愿努力完成某件困难且有价值的事情的过程中，身体或精神达到极限的时刻。如果你想要建造一艘大船，不要立马号召大家开始收集木材，也不要立马分配任务和工作，而是应该先教会他们去憧憬广阔无银的大海。（这就是激励团队的全部要诀。告诉大家要去哪里，通过描述让目标仿佛就呈现在他们眼前，最终使你的目标成为大家的共同愿景。）如果不吸取教训，失败就仅仅是失败。——Scott Cook如果你不希望技术极客流失，就要像办法提拔他们，但不要让他们当管理者。他们多数都不太适合从事管理工作——事实上，他们中的大多数可能会变成可怕的管理者。但你需要给他们提供向上发展的途径，需要给他们认可，需要给他们发更多的工资——Eric Schmidt（20年前，Schmidt提倡设立一个与传统的管理岗位职业阶梯平行的技术岗位职业阶梯）对于用行动支持你想营造的文化的工程师，要给予公开的奖励或感谢——Juanita Mah对工程师来说，最糟糕的事件就是看不到自己的工作成果交付。——Ron Lichty不管团队成员加班是否有加班费，最大的错误都是不对加班进行记录。不能因为团队成员没有加班费就认为那是“免费的”。对于财务部门来说这样认识是对的，但从项目经理的角度来说，加班不是免费的 ——Ed Yourdon项目经理必须当心的一种危险情况是：狂热而又年轻的软件工程师过多地自愿加班——Ed Yourdon侯世达（Hofstadter）定律：做事所花费的时间总是比你预期的要长，即使你的预期中考虑了侯世达定律。——Douglas Hofstadter病态组织的一个症状是：项目人员精简反而会有风险——Tom Demarco复杂性是个要命的东西。它会榨取开发者的生命力，会使产品难于计划、构建和测试，会带来安全性上的挑战，还会使最终用户和管理员垂头丧气——Ray Ozzie[对软件需求而言]我们总是习惯性地以为人们知道自己想要什么，虽然实际的经验更像是：“人们不清楚自己想要什么，但在他们看到东西的时候能分辨出不想要什么” ——Kurt Bittner规格说明中模棱两可的表述，乃是系统利益相关者之间悬而未决的冲突的体现 ——Tom Demarco软件任务中最难的部分是如何得出一份完整一致的规格说明，在很大程度上，程序构建的实质乃是对规格说明进行“调试”。相比于缺少某些功能特性，糟糕的质量更容易引起客户的不满——Mark Calomeni软件很像香肠：享用最终产品时，人们真心不想知道其中加入了什么在实践中，Brooks发现，几乎所有的项目都只有六分之一的时间花在编码上，而整整一半的时间要用在测试和修正bug上。杰出的开发者每编码一小时，就会花上两小时进行测试。测试本身并不能提升软件质量。测试结果只是衡量质量的指标，但并不能改善质量。试图通过增加测试量来提升软件质量，就好比试图通过更频繁的称重来减肥。决定称重结果的是上秤之前吃了些什么，而决定测试出的错误多少的则是所用的软件开发技术。想减肥，就要改变膳食，而不是买一台新秤。要想改善软件，就要更好地进行开发，而不是进行更多的测试。如果你没时间去计算价值，我们就没用时间取计算开销。——Jim Highsmith（至那些要求日程表估计却不愿将特性按优先级排序或提供价值估计的产品的人）当任务由于次序上的限制不能分解时，人手的添加对进度没用帮助。无论指派多少个妇女，孕育一个生命都需要9个月。许多软件任务都具有这样的特征，这是由于调试工作的时序性本质引起的。“学习编程” 与 “设计交互式软件”之间的关系，并不比“学习打字指法”与“写诗”之间的关系更紧密。——Ted Nelson永远不去要求团队做你自己不会去做的事情。在如今这个随时都能沟通的时代，你其实从没有真正离开办公室；你（不幸地）一直在工作，所以以身作则会是更好的方式。确保你在所有的行动中一直树立榜样，包括早到、晚退、如有必要全天待命、为讨论做准备、任何时刻都表现得非常专业、对你的员工和团队说“谢谢”，以及其他能表现你性格的方式管理实践，要成为一个高效的经理，必须首先成为一个高效的沟通者。最高效的沟通者往往都是优秀的倾听者。关注对方反馈型倾听突破沟通障碍了解真正重要的是什么，许多人认为管理是自上而下的，具有权威性的地位，也就是说，处在金字塔的顶端——一山之王。与此相反，我们建议你把自己看成是处于金字塔的底部，而你员工在顶端。他们和他们做的工作才是真正重要的。每天都进步成为解决方案的一部分，而不是问题的一部分跟踪管理日常任务清单 2. 行动项目 3. 提醒事项三个主要的激励理论马斯洛的需求层次理论道格拉斯-麦格雷戈的X-Y理论赫茨伯格的激励因素和保健因素理论赫茨伯格首次展示了，工作中的满意和不满意几乎总是源自不同的因素，并非之前一直认为的对相同因素的不同反应（当然，依然有人坚持这一观点）。赫茨伯格的研究结果表明，一组因素（“激励因素”）能真正起到激励作用，而另一组因素（“保健因素”）则会导致不满意。程序员的激励因素不满的原因导致员工离职内在激励的三大要素，“驱动力3.0”，这三大要素是：自主（或者自我决定），专精（不断进步）及目的（为某个更大的目标服务）庆祝你的成功，在失败中寻找幽默。别太把自己当回事儿。你放松，你周围的人才能放松。享受乐趣，并始终保持激情。程序设计过程中，想要领导团队达到最高效率，需要创造一种文化，鼓励互相尊重，创新，守则，对交付和卓越的期待，高效的交流，公平，授权，专业，团队合作，激情，客户至上，以及追求技术卓越。互相尊重，需要团队对你尊重，也需要给予团队你的尊重。这两者还不够，创建一种团队成员彼此互相尊重的文化，才应该是最终目标。未达成这个目标，需要leader先做出表率，建立一种礼貌，尊重和互相关心的文化创新，产品经理和你的客户可能决定了“做什么”，你的程序员则决定了“如何去做”，而选择最好的“如何去做”，需要付出大量的思考和创造。标准。标准不能随意定制：每一条都必须是有意义的。交付。沟通。只有通过充足的沟通，你才能确保团队中的每个人都朝着正确的方向前进。同场工作的程序员，能体验到彼此的节奏，可以在办公室外随意闲聊其工作进展，也能吸引到同事的注意，向他们请教设计或调试的问题。虚拟团队间的沟通。虚拟团队必须致力于以超出同地点团队的水平去沟通：更多的交流，更多的电子邮件，更多的在团队wiki上的分享，更好的文档，更多的语音和即时通讯沟通。你需要监控交谈渠道，确保他们在交流。团队成员之间相隔越远，沟通应越正式越明确。公平。公平的程序设计文化会让你的员工放心工作，因为他们知道奖励（或批评）都是公平的，而不是武断专制的。授权。虽然新程序员需要指导（甚至经验丰富的程序员面对新的环境时也需要），但没有什么比授权让他们自主更能促进工作效率的了。职业精神。拒绝傻瓜和笨蛋。卓越。一种鼓励、要求并期待卓越的文化，获得卓越表现的可能性会大得多。程序设计上的卓越团队精神和协作。应当在奖励团队和奖励英雄之间建立合理的平衡，然后就会有很多团队成员愿意帮你挽救危局，而实际上，他们需要那么做的情况却少得很多。激情。激情是发自内心的情感——来自每个人之所以存在的核心之处。激情源于你对自己的认识，对自己所在意的事情的理解，以及你和你的所作所为之间的直接联系。关注客户。 大多数程序可以通过让开发人员“吃自己做的狗粮”（实际使用自己开发的软件）而得到改进。学习。开发组织应当是一个学习型组织。环境。关于需求的最重要定理是:”想尽办法把需求搞对，理解客户真正需要什么，剩下的事情就都好办多了“在为了项目估计而拆分任务的时候，任务应当达到最少需要2天工时，小到不超过一周的开发时间。招聘更多的程序员，在短期内会拖慢你的进度。只有完成一次项目之后，新程序员才能够真正帮到你。不要轻易地认为你可以直接分配任务给新程序员，而忽略他们执行效率更低、需要指导的事实。开发是一个三角形：质量好、速度快、开销省、（功能多）——只能任选两个基本上，如果需要增加功能，那么为了满足相同的截止日期，必须采取以下措施之一：减少其他规模类似的功能；减少质量的保证；改变截止日期带给团队更多时间；增加更多资源。功能、质量、时间和资源的洽谈是一项艺术。给出现实的情况，然后总是给出三种选项——三种不同的方案可供选择。功能需求点总是多到来不及实现；软件缺陷也总是躲到来不及全部修复。项目永远无法达到完美的。总会有bug。总会有可以继续改善的地方。软件永远无法完全完善。“有正确设计思想方法的技术”未必能够成功，因为还有非技术的因素；但“没有正确设计思想方法的技术”一定失败，无一例外。本文地址： https://leaf0s.fun/2018/08/20/1467955973/]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Centos7 下安装docker-ce]]></title>
    <url>%2F2018%2F06%2F14%2F427468595%2F</url>
    <content type="text"><![CDATA[Centos7 下安装docker-ce目前docker版本都更新到了docker-ce, 对各个系统的支持也越来越好. 这里以Centos7为基础, 来说明下如何安装docker-ce一. 安装依赖库1yum install -y yum-utils device-mapper-persistent-data lvm2 epel-release lrzsz vim net-tools bash-completion wget bridge-utils二. 由于docker.com 被国内屏蔽了，所以按照如下的方法进行安装，可能行不通：12345yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 换成aliyun的(http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo)# (yum-config-manager --add-repo ./docker-ce.repo)yum --enablerepo=docker-ce-stable clean metadatayum install docker-ce三. 如果步骤1通过docker的源无法安装, 也可以下载到本地安装1yum install ./docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm查看是否安装成功1yum list docker-ce --showduplicates | sort -r四. 安装好docker后，通过systemd来管理12systemctl enable dockersystemctl start docker五. 运行hello-world镜像1docker run hello-world会自动下载镜像，输出hello world查看下载的镜像 docker image ls查看运行容器 docker ps六. 安装并运行最小 ubuntu的镜像，需要挂代理1docker run --rm -t -i phusion/baseimage:v0.10.1 /sbin/my_init -- bash -l七. 后续内容参考文档 https://yeasy.gitbooks.io/docker_practice/install/centos.htmldocker info 命令来查看 docker的信息推荐使用DaoCloud的镜像来加速1curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://f1361db2.m.daocloud.io在/etc/docker/daemon.json 文件中加入123&#123; "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"]&#125;docker search centos如果报错, 修改dns为8.8.8.8八. 扩展工具安装监控工具安装ctop来,对docker所有运行的容器进行监控12wget https://github.com/bcicen/ctop/releases/download/v0.7.1/ctop-0.7.1-linux-amd64 -O /usr/local/bin/ctopchmod +x /usr/local/bin/ctop安装compos工具123curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-Linux-x86_64 -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composecurl -L https://raw.githubusercontent.com/docker/compose/1.22.0/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose后续可能需要docker-slim 工具 对docker进行瘦身docker-gc 进行收集垃圾容器和镜像watchtower 用来监控镜像九. 问题和命令举例register cache 配置，配置成了cache，将不能push12345Meanwhile thats possible:https://blog.docker.com/2015/10/registry-proxy-cache-docker-open-source/https://docs.docker.com/registry/recipes/mirror/But Pushing to such a registry is not supported:https://docs.docker.com/registry/configuration/#proxydocker 的日志 目前 输入到了 /var/log/message 中了查看网桥1brctl show在运行的容器中执行命令1docker exec -i -t mynginx /bin/bash查看镜像所占的空间1docker system df保存和加载镜像123docker save alpine | gzip &gt; alpine-latest.tar.gzdocker load -i alpine-latest.tar.gzdocker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; 'cat | docker load'docker run 执行的动作逻辑检查本地是否存在指定的镜像，不存在就从公有仓库下载利用镜像创建并启动一个容器分配一个文件系统，并在只读的镜像层外面挂载一层可读写层从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去从地址池配置一个 ip 地址给容器执行用户指定的应用程序执行完毕后容器被终止导出和导入容器快照12docker export 7691a814370e &gt; ubuntu.tarcat ubuntu.tar | docker import - test/ubuntu:v1.0管理敏感数据123openssl rand -base64 20 | docker secret create mysql_password -docker secret lsdocker service create --name mysql --replicas 1 --network mysql_private --mount type=volume,source=mydata,destination=/var/lib/mysql --secret source=mysql_root_password,target=mysql_root_password --secret source=mysql_password,target=mysql_password -e MYSQL_ROOT_PASSWORD_FILE="/run/secrets/mysql_root_password" -e MYSQL_PASSWORD_FILE="/run/secrets/mysql_password" -e MYSQL_USER="wordpress" -e MYSQL_DATABASE="wordpress" mysql:latest查看docker 容器或镜像的具体信息12docker image ls --format "&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Size&#125;&#125;"| sort -n | uniq -cdocker inspect -f "&#123;&#123;.Config.Cmd&#125;&#125;" 3929查找docker的进程号:1docker inspect -f '&#123;&#123;.State.Pid&#125;&#125;' &lt;containerid&gt;查看连接1sudo nsenter -t &lt;pid&gt; -n netstat | grep ESTABLISHED要解决docker宿主机和容器之间时间不一致的情况,有三种解决方法:共享主机的localtime. 创建容器的时候指定启动参数，挂载localtime文件到容器内，保证两者所采用的时区是一致的。1docker run --name &lt;name&gt; -v /etc/localtime:/etc/localtime:ro ....复制主机的localtime1docker cp /etc/localtime:【容器ID或者NAME】/etc/localtime在完成后，再通过date命令进行查看当前时间。但是，在容器中运行的程序的时间不一定能更新过来，比如在容器运行的mysql服务，在更新时间后，通过sql查看mysql的时间select now() from dual;可以发现，时间并没有更改过来。这时候必须要重启mysql服务或者重启docker容器，mysql才能读取到更改过后的时间。通过dockerfile来修改时间创建自定义的docker文件, 自定义了镜像的时间格式及时区123456FROM redisFROM tomcatENV CATALINA_HOME /usr/local/tomcat#设置时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ &amp;&amp; echo 'Asia/Shanghai' &gt;/etc/timezone \本文地址： https://leaf0s.fun/2018/06/14/427468595/]]></content>
      <categories>
        <category>技术实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[企业安全入门读书笔记]]></title>
    <url>%2F2018%2F03%2F12%2F483110212%2F</url>
    <content type="text"><![CDATA[企业安全入门笔记安全理论模型PDR模型：Protection(保护)、Detection(检测)、Response(响应)三个部分。在这个模型下, 企业安全的各个产品分布开源软件在该模型下的分布防御体系甲方安全的主要职责是保护公司互联网业务安全，比如：业务持续性、业务数据的私密性。所以要优先解决以下问题：1）抗DDOS 2）防拖库 3）防后门常见的防御体系：边界防御体系纵深防御体系。在Web领域至少会包含下面几层，数据库端、服务器端、网络层、网络边界。河防体系。河防体系特别适合数据中心用户塔防体系。云+端+边界+联动下一代纵深防御体系。威胁情报好比是积累的知识，大数据和人工智能好比是聪明的大脑，WAF、SIEM、服务器安全等好比是有效的武器，大家互相配合，实现了下一代的纵深防御，在对已知威胁有较好的防御能力外，对于未知威胁也具有一定防御能力WAF产品传统WAF在安全方面存在以下几个问题1）防护能力不足以应对黑产2） 缺乏有效的基础业务安全防护能力3） 审计能力不足理想中的WAF1） 上下文理解能力2） 语义分析能力3） 机器学习能力4） 审计取证能力5） 威胁情报能力6） 业务安全防护能力7） 协同能力分布式WAF集群架构主要包括：四层负载均衡、WAF服务、WAF日志处理、WAF配置管理。每个部分均支持集群部署，快速横向扩展。分布式WAF架构使用LVS做负载均衡使用zookeeper做配置管理使用storm做实时流式处理，使用Spark做离线分析，基于HDFS做离线存储，实时检索原始日志的需求使用ElasticSearch。日志分析：1）统计实时拦截报表 2）统计实时访问PV/UV 3）离线分析小时/天/周/月的PV/UV 4）离线保存原始日志 5）运行HMM分析漏报 6）运行语义分析漏报应用实时防护（RASP）应用实时防护，又称RASP，以探针的形式，将保护引擎注入到应用服务中，可在文件、数据库、网络等多个层面，对应用进行全面的保护。当发生敏感的行为时，可以结合请求上下文进行判断，并阻断攻击，具有低误报率，低漏报率的优点。WAVSEP（Web Application Vulnerability Scanner Evaluation Project）靶场，用于搭建测试环境。WAVSEP是一个包含漏洞的Web应用程序，目的是帮助测试Web应用漏洞扫描器的功能、质量和准确性。baidu：openrasp业务网安全域业务网安全域的划分：1.办公区 2.业务区 3.外网 4.办公服务区 5.开发测试服务区主机安全资产管理信息收集和使用业务服务器上需要部署osquery以及一个负责在ZooKeeper订阅命令的脚本，并将查询的结果发送给Kafka集群。管理服务器负责向ZooKeeper发送需要执行的SQL命令以及搜集Storm集群计算的结果，Storm处理服务器osquery查询的结果，根据规则将处理结果发送给管理服务器。威胁情报威胁情报：基于证据的知识，包括上下文、机制、指标、隐含和可操作的建议，针对一个先存的或新兴的威胁，可用于做出相应决定的知识。主要包括文件Hash值、IP地址、域名、网络或主机特征、攻击工具和TTPs（Tactics、Techniques &amp; Procedures）常见的开源威胁情报源包括以下几个：名称特点ThreatMinerfor IPv4, FQDN，MD5 and SHA2 lookupsAlienvaultOTX for IPv4, MD5 and SHA2 lookupsIBM X-ForceExchange for IPv4 lookupsVirusTotalfor MD5 and SHA2 lookupsCymon.iofor IPv4 lookupsCIRCL(Computer Incident Response Center Luxembourg) for CVE LookupsPassiveTotalfor FQDN Whois Lookups常见的威胁情报指标器包括以下几种形式：IPv4，MD5，SHA2，CVE，FQDN威胁情报和SOC系统联动网关Kong: API 网关Nebula：业务风控系统开源代码审计RIPS：使用PHP语言编写的，用于静态审计PHP代码的安全性VCG（Visual Code Grepper）：支持C/C++，C#，VB，PHP，Java和PL/SQL的免费代码安全审计工具。一款基于字典的检测工具，功能简洁，易于使用。蜜罐蜜罐突出的特点就是误报率低，准确度高。开源蜜罐Glastopf，一款Web服务蜜罐，项目地址为：https://github.com/glastopf/Kippo，是一款优秀的SSH服务蜜罐，它提供了非常逼真的shell交互环境，项目地址为：https://github.com/desaster/kippoElasticpot，ElasticSearch服务蜜罐，项目地址为：https://github.com/jordan-wright/elastichoneyrdpy-rdphoneypot，RDP服务蜜罐，项目地址为：https://github.com/citronneur/rdpyConpot是一个开源的ICS/SCADA蜜罐，可以实现ModBus SNMP等PLC的外部子站服务的模拟仿真，项目地址为：http://conpot.org/Dionaea是低交互式蜜罐，是Nepenthes（猪笼草）项目的后继，项目地址为：http://edgis-security.org/honeypot/dionaea/amun与Dionaea类似，也是一款低交互式蜜罐，主要用于搜集恶意程序，项目地址为：https://sourceforge.net/projects/amunhoney/wordpot是一款模拟wordpress服务的蜜罐，项目地址为：https://github.com/gbrindisi/wordpotshockpot与Glastopf类似，是一款Web服务蜜罐，项目地址为：https://www.anomali.com/blog/shockpot主动欺骗型蜜罐：BeeswarmBeeswarm由Beeswarm Server、Beewarm Drone Client 和 Beewarm Drone Honeypot组成。Beeswarm Drone Client伪装成真实用户或管理员，向Beeswarm Drone Honeypot发起访问，访问流量中会故意携带明文的用户信息或者登录口令，诱骗攻击者。Beeswarm Server收集Beeswarm Drone Client 和 Beeswarm Drone Honeypot 上报的攻击信息，然后进行综合判断。蜜罐与SOC集成，蜜罐通常可以作为一类数据搜集器扩展SOC的数据源，蜜罐本身既可以产生相对高质量的报警，同时也可以作为原始数据源提供给SOC，SOC通过关联分析多数据源后，会做出更全面精准的判断。蜜罐联动WAF、SOCMHN（Modern Honey Network）：蜜罐管理和数据收集服务，集成了多种蜜罐统一管理，并且集成了Snort，可以针对攻击行为进行攻击类型标记。MHN使用开源蜜罐来收集数据，整理后保存在mongodb中，收集到的信息也可以通过Web接口来展示或者通过开发的API访问，这里统称为WebApp。MHN能够提供多种开源的蜜罐，可以通过Web接口来添加他们。态势感知态势感知由以下几个重要组成部分：漏洞扫描、入侵感知以及安全可视化、敏感信息泄露健康等内容。常见的Web扫描器：Nikto、Paros proxy、WebInspect、OWASP ZAP、Burpsuite、IBM Security AppScan、Acunetix Web Vulnerability Scanner、SQLmap基于Celery的Web扫描器系统架构基于Celery的扫描系统工作流程Celery 和 Docker技术结合起来完成分布式部署，同时为了提高Redis的性能和容量，会使用集群模式，整个系统通过Docker集群可以非常方便地根据性能情况动态调整Celery中扫描Worker的数量，通常一个worker对应一个Docker实例。端口扫描的主要目标是：1.发现对外违规开放哦端口 2.发现在合法端口开放的违规服务 3.端口扫描还可以作为资产搜集的一个渠道。nmap基本功能有三个：1.探测一组主机是否在线 2.扫描主机端口，嗅探所提供的网络服务 3. 推断主机所用的操作系统。zmap比nmap快 1300倍， zmap采用了无状态的扫描技术，没有进行完整的TCP三次握手，因此极大地提升了扫描速度。masscan也是无状态扫描，所以性能相对nmap，得到了大幅提升入侵感知又称为入侵检测系统攻击链模型Web系统的入侵检测系统：从协议栈的角度分析，需要覆盖至少HTTP协议、数据库协议、DNS协议从数据搜集的角度分析，需要覆盖至少网络流量，数据库日志，Web服务器文件，服务器操作日志，DNS服务器查询日志，最好再包括服务器进程信息，PHP/JAVA组件内部调用数据，甚至业务层应用日志。网络入侵检测系统常见的网络全流量获取方式为交换机镜像、分光镜和网络分流器三种。协议分析主要包括：1.包重组 2.TCP/UDP会话还原 3.应用层协议解析libpcap主要有以下作用：捕获各种数据包，例如：网络流量统计。过滤网络数据包，例如：过滤掉本地上的一些数据，功能类似防火墙。分析网络数据包，例如：分析网络协议，数据的采集。存储网络数据包，例如：保存捕获的数据以备将来分析使用。libpcap通常出来10M左右的流量时表现良好，超过10M以上流量时性能明显下降。PF_RING处理1个G的流量是没问题的大流量下可以使用DPDK，使用双网卡结合DPDK单机处理20G的案例bro 是一款被动的开源流量分析器，它主要用于对链路上所有深层次的可疑行为流量进行安全监控。bro通常作为全流量的协议解析。bro支持分布式架构，用于处理大流量，其中主要组成部分为Frontend、Manager、Proxy 和 WorkerFrontend直接对接网路流量，并且把流量按照五元组或者直接按照IP将流量负责均衡到Worker上进行分析。事实上Bro并没有实现Frontend，通常Frontend可以使用专业的TAP设备或者使用交换机完成。Manager统一接受来自Worker分析处理后的数据，统一记录日志或者按照要求发送给Kafka。Manager属于硬盘消耗型，对IO和存储都有消耗。Proxy用于帮助Worker之间同步状态信息，便于Worker跨进程甚至跨主机同步状态数据。Proxy性能消耗不大，通常可以和Manager混布。Worker是实际负责流量处理协议分析的工作单元，为了尽可能提高效率，Worker的处理都在内存中进行，几乎不需要使用硬盘资源，属于计算和内存使用型。根据Bro的官网说明，Worker的一个核可以承载最多250Mbps的流量的分析，也就是说如果要处理2个G的流量，至少需要8个核。suricata 是一款网络入侵检测和阻止引擎软件，该引擎是多线程的，内置对IPV6的支持，可加载预设规则，支持Barnyard和Barnyard2工具，Suricata的架构图如下：全流量的安全分析基于规则的分析：单向报文分析，双向报文分析（简单地讲就是关联分析请求和应答内容，如果请求中存在攻击特征，并且应答内容中出现对应的漏洞利用成功的内容，就可以判断攻击成功了），威胁情报基于时序的分析，心跳特征基于语义的分析，webshell注入，XSS、SQL注入基于沙箱的分析，或联动沙箱，文件检测基于机器学习的分析基于行为的分析*主机入侵检测常见的开源主机入侵检测软件当属OSSEC。OSSEC是一款开源的、多平台的入侵检测系统，可以运行于Windows、Linux、OpenBSD/FreeBSD以及MacOS等操作系统中，包括了日志分析和Rootkit检测等。OSSEC支持C/S架构，同时也支持不安装客户端的情况，通过syslog协议接受日志分析。OSSEC支持单机版和分布式版本，其中分布式版本为典型的C/S架构，分为server和agent。分布式OSSEC不仅可以支持agent直接搜集数据分析，还可以直接在不安装客户端的情况下，通过syslog等协议远程接受数据并分析，比如防火墙、路由器以及可以发送syslog的操作系统和安全设备都属于OSSEC架构，所以从某种角度来说，OSSEC也是一种SIEM/SOC软件。OSSEC的核心功能可以概括为以下几个方面：日志分析。通过分析日志，发现异常行为文件完整性检查。监控操作系统中关键文件的修改情况，及时发现篡改行为RootKit检测。检测Linux系统常见的RootKit行为。动态响应。根据日志分析、文件完整性检测或者RootKit检测的结果，进行动态响应，包括但不限于防火墙封禁、账户禁用等。OSSEC内部数据处理过程：先经过预解码、解码完成后、再匹配规则物联网IOT以及工控设备ICS入侵检测Sweet Security是基于Bro和ELK的针对IOT和ICS的安全监控软件。它通过Bro支持常见的DNS、HTTP等协议，同时支持了Modbus和DNP3协议。Sweet Security通过监控IOT和ICS的通信流量，识别攻击行为，甚至是基于Modbus和DNP3协议的攻击，攻击的结果会保存在本地，并且支持进一步发送给ELK或者常见的日志搜集系统，比如SOC。支持以下操作系统：Raspbian JessieDebian JessieUbuntu 16.04目前支持的硬件平台：RaspberryPi 3x86x86_64推荐的硬件配置为：ARM，x86，or x86_64 CPU2GB RAM8GB Disk Storage100 MB NICSweet Security也支持分布式部署，一个推荐的分布式架构如图所示，该架构包括分别执行ARP Spooling、Network Scans 和 Bro IDS Inspection 的三个客户端和一个基于Web的服务器。SOC常见的开源SOC软件主要有：OSSIM 和 OpenSOC。OSSIM即开源安全信息管理系统，是一个非常流行和完整的开源安全架构体系。OSSIM由数据收集、监视、检测、审计以及控制台这五个模块构成。这五个模块包含了目前安全领域内从事件预防到事件处理的一个完整过程，在目前的安全架构中，OSSIM是最为完备的。这五个功能模块又被划分为三个层次，分别是高层的安全信息显示控制面板、中层的风险和活动监控以及底层的证据控制台和网络监控，各个层次提供不同功能，共同保证系统的安全运转。在OSSIM中，整个过程处理被划分为两个阶段，这两个阶段反映的是一个事件从发生到处理不同的时期。这两个阶段分别为预处理阶段，这一阶段的处理主要由监视器和探测器来共同完成，主要是为系统提供初步的安全控制；以及事后处理阶段，这一阶段的处理更加集中，更多的是反映在事件发生之后系统安全策略的调整和整个系统的安全配置的改进。在OSSIM的架构体系中，有三个部件比较引人注意，即OSSIM中的三个策略数据库，是OSSIM事件分析和策略调整的信息来源，分别为以下三种数据库：EDB（事件数据库）：在三个数据库中，EDB无疑是最大的，它存储了所有底层的探测器和监视器所捕捉到的所有的事件。KDB（知识数据库）：在知识数据库中，将系统的状态进行了参数化的定义，这些参数将为系统的安全管理提供详细的数据说明和定义。UDB（用户数据库）：在用户数据库中，存储了用户的行为和其他与用户相关的事件。OpenSOC是各种开源大数据架构和安全分析工具的有机结合。OpenSOC主要由数据源系统、数据收集层、消息系统层、实时处理层、存储层和分析处理层组成。目前OpenSOC已经加入Apcache并改名为Apache MetronOpenSOC主要功能包括：可扩展的接收器和分析器能够监视任何数据源。支持对数据流的异常检测和基于规则的实时告警。支持使用Elasticsearch实现自动化实时索引数据流。支持使用Hive利用SQL查询存储在Hadoop中的数据。能够兼容ODBC/JDBC和继承已有的分析工具。具有丰富的分析应用功能且能够集成已有的分析工具。支持自动生成报告和异常报警。支持原始网络数据包的抓取、存储和重组。SOC的数据源常见的包含以下六种：1. 网络流量 2. 文件 3. Syslog 4. SNMP 5. 数据库 6. 爬虫网络全流量包含完整的网络数据，即TCP/IP协议栈的数据，比如：MAC头、IP头、TCP头、HTTP头以及HTTP载荷数据，对于分析网络中的攻击行为帮助非常大。Netflow提供网络流量的会话级视图数据收集层数据收集层常用软件包括Logstash和Flume，针对网络全流量收集还有Bro软件。消息系统层消息系统是整个机器学习框架的信息高速公路，数据的进出都依赖于它。最常使用的消息系统是KafKa。KafKa系统由以下几个部分组成：Broker，Topic，Parition，Consumer Group. KafKa通过ZooKeeper管理集群，选举leader。实时处理层实时处理层主要使用Storm，Storm是一个免费开源、分布式、高容错的实时计算系统。Storm主要分为Nimbus和Supervisor两种组件，这两种组件本地都不保存状态，任务状态和心跳信息等都保存在Zookeeper上，提交的代码资源都在保存本地机器的硬盘上。Storm提交运行的程序称为Topology，Topology处理的最小消息单位是一个Tuple，也就是一个任意对象的数组。Topology由Spout和Bolt构成。Spout是发出Tuple的结点。Bolt可以随意订阅某个Spout或者Bolt发出的Tuple。Spout和Bolt都统称为component。存储层HDFS，Hadoop分布式文件系统(HDFS)，HDFS是一个主从结构，一个HDFS集群具有一个名字节点(Namenode)，它是一个管理文件命名空间和协调客户端访问文件的主服务器；还有一些数据节点(Datanode)，通常是一个节点一个机器，它来管理对应节点的存储。HDFS对外开放文件命名空间并允许用户数据以文件形式存储和访问。其内部机制是将一个文件分割成一个或多个块，这些块被存储在一组数据节点中。名字节点用来操作文件命名空间的文件或目录，如打开，关闭，重命名等，同时确定块与数据节点的映射。数据节点负责来自文件系统客户的读写请求，同时还要执行块的创建，删除和来自名字节点的块复制指令。名字节点是仲裁者和所有HDFS元数据的仓库，用户实际数据的读写不经过名字节点。HBase，HBase是一个高可靠、高性能、面向列、可伸缩的分布式存储系统。HBase利用Hadoop HDFS作为其文件存储系统。HBase利用Hadoop MapReduce来处理HBase中的海量数据，利用ZooKeeper作为协同服务。Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变得非常简单，Sqoop则为HBase提供了方便的RDBMS数据导入功能。HBase由以下几个组件构成：HBase Client使用HBase的RPC机制与HMaster和HRegionServer进行通信，对于管理类操作，Client与HMaster进行RPC；对于数据读写类操作，Client与HRegionServer进行RPC。Zookeeper中除了存储-ROOT-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。HMaster没有单点故障问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行，HMaster在功能上主要负责Table和Region的管理工作。HRegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块。ElasticSearchMarvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。./bin/plugin -i elasticsearch/marvel/latest禁用监控，可以通过以下命令关闭Marvelecho ‘marvel.agent.enabled: false’ &gt;&gt; ./config/elasticsearch.yml离线分析处理层Spark，Apache Spark是专为大规模数据处理而设计的快速通用的计算引擎。Spark拥有Hadoop MapReduce的所有优点，但不同于MapReduce的是，Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce算法TensorFlow，TensorFlow是一个采用数据流图，可用于数值计算的开源软件库。节点在图中表示数学操作，线在图中表示节点间相互联系的多维数据数组，即张量。SOC普遍的数据收集流程流式处理过程storm中Linux服务器账户被盗检测逻辑图数据库安全开源数据库主机端审计mysql-audit开源数据库流量审计MySQL sniffer，全流量采集，协议分析开源数据库防火墙DBProxy数据防泄漏本文地址： https://leaf0s.fun/2018/03/12/483110212/]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[项目管理学读书笔记]]></title>
    <url>%2F2018%2F03%2F12%2F1343718827%2F</url>
    <content type="text"><![CDATA[项目管理学读书笔记最近读了基本项目管理学的书, 记录下收获和感受.卓有成效的管理者读书笔记管理的职能就是计划、组织、整合、激励和考核管理者的困境：管理者的时间往往只属于别人，不属于自己。组织的囚徒。管理者往往被迫忙于”日常运作“，除非他们敢于采取行动来改变周围的一切。无法判断什么是真正重要的事项。管理者本身处于一个”组织“之中。只有当别人能够利用管理者的贡献时，管理者才算有效。知识工作者彼此之间最难协调，其原因正是由于他们是知识工作者。贡献在于”旁系人士“或是管理者本人的上司。管理者身处一个组织的”内部“，受到组织的局限。在组织的内部，不会有成果出现，一切成果都存在于组织之外。在组织内部只有人工和成本。我们既然不能增加资源的供应量，就应该设法增加资源的产出量。所谓有效性，就是使能力和知识资源能够产生更多更好成果的一种手段。卓有成效的管理者必须在思想上养成的习惯：有效的管理者知道他们的时间用在什么地方。他们所能控制的时间非常有限，他们会有系统地工作，来善用这有限的时间有效的管理者重视对外界的贡献。他们并非为工作而工作，而是为成果而工作。”别人期望我做出什么成功“有效的管理者善于利用长处，包括自己的长处、上司的长处、同事的长处和下属的长处。他们还善于抓住有利形势，做他们想做的事。他们不会把工作建立在自己的短处上，也绝不会去做自己做不了的事有效的管理者集中精力于少数重要的领域，在这少数重要的领域中，如果能有优秀的绩效就可以产出卓越的成果。他们会按照工作的轻重缓急设定优先次序，而且坚守优先次序。最后，有效的管理者必须善于做有效的决策。他们知道有效的决策事关处事的条理和秩序问题，也就是如何按正确的次序采取正确的步骤。他们知道一项有效的决策，总是在“不同意见讨论”的基础上做出的判断，它绝不会是“一致意见”的产物。他们知道快速的决策多为错误的决策，真正不可或缺的决策数量并不多，但一定是根本性的决策。他们需要的是正确的战略，而不是令人眼花缭乱的战术。掌握自己的时间：记录时间管理时间统一安排时间每一位知识工作者，尤其是每一位管理者，要想有效就必须能将时间做整块的运用。如果将时间分割开来零星使用，纵然总时间相同，结果时间也肯定不够。沟通和交流很重要，如果没有交流，知识工作者就容易丧失热情，成为得过且过的人，或者是只关注自己的专业领域，看不到整个组织的需要和机会。人数越多，协调相互关系所需的时间越长，而真正用于工作的时间便相对地减少了减少时间浪费的方式;首先要找出什么事根本不必做，这些事做了也完全是浪费时间，无助于成果。哪些事情或者活动可以由别人代为参加而又不影响效果管理者在浪费别人的时间人总有一种倾向，高估自己地位的重要性，认为许多事非躬亲不可时间浪费的原因:由于缺乏制度或远见而产生时间浪费的因素。应注意的现象，是机构中一而再、再而三出现同样的“危机”人员过多，也常造成时间浪费.因为大家的时间，可能没有花在工作上，而是用来协调人员之间的关系了。工作时间的1/10花在处理所谓“人际关系问题”上另一个常见的浪费时间的原因，是组织不健全。其表现就是会议太多. 所谓会议，顾名思义，是靠集会来商议，是组织缺陷的一种补救措施,会时就不能工作，工作时就不能开会，谁也不能同时又开会又工作. 一个结构设计臻于理想的组织，应该没有任何会议最后一项浪费时间的因素，是信息功能不健全.同样常见的现象，是信息的表达方式不当。其后果有时更为严重时间管理的最后一步，应该是将可由管理者自行支配的零碎时间集中起来。专业人员必须使他本人有效，必须使他的专长有效。他必须考虑到他的产出供什么人使用，也必须了解用户应该知道些什么才能有效使用他的产出，从而产生成果。有效的人际关系，有下列四项基本要求：互相沟通，沟通是双向的，上下互相沟通团队合作，强调贡献有助于横向的沟通，因此能够促成团队合作自我发展，个人能否有所发展，在很大程度上要看你是否重视贡献培养他人，重视贡献的管理者必然会同时启发他人有效的管理者在会议开始时，会先说明会议的目的和要求达成的贡献有效的管理者能使人发挥其长处。他知道只抓住缺点和短处是干不成任何事的，为实现目标，必须用人所长——用其同事之所长、用其上级之所长和用其本身之所长。利用好这些长处可以给你带来真正的机会。充分发挥人的长处，才是组织存在的唯一目的。要知道任何人都必定有很多缺点和短处，而缺点和短处几乎是不可能改变的。但是我们却可以设法使其不发生作用。管理者的任务，就是要充分运用每一个人的长处，共同完成任务。如何管理上司要使上司能发挥其所长，不能靠唯命是从，应该从正确的事情着手，并以上司能够接受的方式向其提出建议。领导人和一般人之间总有一段差距。领导人的绩效高了，一般人也竞相争高。有效的管理者一定明白这层道理：提高领导人的水平容易，但提高全体人员的水平很难。所以，他一定要找出有条件做出突出贡献，并能起带头作用的人才，赋予他们领导人的地位，把他们安置到能“制订标准”并能创造成绩的位置上。卓有成效的秘诀是善于集中精力。卓越成效的管理者总是把重要的事情放在前面先做（first tings first），而且一次只做好一件事（do one thing at a time）。管理者越是想做重大的贡献，越是需要有更长的“整块时间”。管理者越是想将繁忙纷杂转化为成就，越是需要持续不断的努力，越是需要较长的连续性的时间。有效的管理者打算做一项新的业务，一定先删除一项原有的业务。这对控制组织的“膨胀”是非常必要的。“膨胀”如不加以控制，组织就会变得涣散、难以管理。社会组织恰如生物有机体，必须保持小而精的状态。（摆脱昨天）先后次序的考虑我们要做的并不只是弄清楚哪些事情必须优先去做，那是很容易做到的，每个人都可以做得到。很多管理者不能做到集中精力于某项工作，其主要困难在于他们确定不了哪些事情可以缓一缓，就是说要能确定哪些事情可以暂时不去做，并且能把这一决定坚持到底。决策的五个要素要确实了解问题的性质，如果问题是经常性的，那就只能通过一项建立规则或原则的决策才能解决。要确实找出解决问题时必须满足的界限，换言之，应找出问题的 “边界条件”。仔细思考解决问题的正确方案是什么，以及这些方案必须满足哪些条件，然后再考虑必要的妥协、适应及让步事项，以期该决策能被接受。决策方案要同时兼顾执行措施，让决策变成可以被贯彻的行动。在执行的过程中重视反馈，以印证决策的正确性及有效性。人件管理者的作用不是让大家去工作，而是创造环境，让大家可以顺利开展工作。在单一思考的工作时间里，理想情况下人们处于心理学家称为“流”（Flow）的状态中。流是一种深度的近乎冥想的融入情况。在这种状态下，有一种普适幸福感存在，人们几乎不会意识到时间的流逝：“我开始工作。等我抬头一看，三个小时就过去了“。 这里不会有工作量的感知；工作开展就像流一样自然。一代人的科技会成为下一代人的环境。团队自毁技巧清单防御式管理官僚主义物理分隔时间碎片牺牲产品质量伪造截止日期团伙控制空洞的口号变态的加班团队形成的化学反应建立对质量的执著追求提供诸多满意的闭环建立精英意识允许和鼓励差异性维护和保护成功团队提供战略而不是战术方向优质管理的四大要素：选择正确的人为他们分配正确的工作保持他们的积极性帮助团队凝聚起来并保持团队的凝聚力（其他一切都只是“文案”）安全和变化:除非感到安全,否则人们就不能去迎接变化在所有成功的工程中(以及在绝大多数其他有价值的工作中)，变化都是基本的要素之一安全感的缺乏会让人们反对变化逃避风险是致命的，因为这会让你也得不到与风险同在的利益人们可能会因为来自客观世界的直接的恐吓和觉得没有安全感，但是如果察觉到管理者可能滥用权力来惩罚自己，他们也会觉得没有安全感负面效应威胁不是提高业绩最好的方法如果分配的时间一开始就不够，不管威胁有多么吓人，工作也无法按时完成更糟糕的是，如果目标没有实现，你就必须兑现你的威胁什么值得做：基本条件是否成熟顶头上司是否值得信任承担这一切是否具有挑战性一切的努力是否能得到足够的回报自己是否胜任管理者必需的身体部位管理涉及到心、肠胃、灵活和鼻子因此：用心来领导，相信你的肠胃（相信你的预感），构筑团队的灵魂，训练一个能嗅得出谎言的鼻子项目成功的关键是让人们能够更有效地在一起学习。如果他们完全分散工作，如果只是一些彼此不认识的在不同地方工作，那么灵魂就无所谓了。管理也就简单了，只需要协调他们的工作就可以，这就成了一个完全机械化的事情了。现实的世界要求团队成员之间有紧密的、温暖的甚至是亲密的联系，还要求组织内部有简单而有效的交流用指挥战争来作为管理的一个比喻在战役开始的时候, 管理者真正的工作已经完成了面试和招聘招聘涉及到所有与管理相关的身体部位：心、灵魂、鼻子和肠胃（但是主要是肠胃）不要试图单独去招聘：两幅肠胃远比一副肠胃的两倍要好对于新的雇员，让他们承担与以前曾经成功过的同样难道的项目，把有挑战性的目标推迟到下一次征求提示：你最希望雇的那个人可能还知道其他很好的人选多听，少说如果先把材料整理好，那么所有的事情都会进行得更好生产力的提高没有“短期生产力提高” 这样的东西生产力的提高是来自长期投资的任何承诺立刻见效的东西都很可能是江湖游医所卖的万灵油风险控制通过控制风险来管理项目为每个项目创建并维护风险统计表跟踪根源性的风险，而不只是最后那讨厌的结果评估每种风险具体化的概率和可能造成的开销对于每种风险，预测标志其具体化的早期征兆任命一个风险控制官，这个人不应该维护组织内部“我能行”的态度建立简单的（可能是匿名的）通道，让坏消息能传递到高层防止失败壮士断腕控制住失败比优化成功更能提高你全面的成绩除非有必要，否则就不要自己去凝聚一个团队：出去找一个已经成型的团队来用保持好的团队在一起（只要他们自己愿意），以帮助你的继任者避免团队凝聚得慢或者不能凝聚的问题把凝聚在一起的团队——准备好，并且也愿意接受新的工作——作为项目的收获之一项目开始浪费的一天和最后阶段浪费的一天对项目造成的伤害是同等的有无数中方法可以浪费一天的时间，但是没有任何一种方式可以拿回一天的时间团队的总生产率影响因素团队可用人员数还没有融入团队的新成员数交流损失融合开销交流损失是一个静态的值，损失值应该是时间动态函数，团队随着共同工作的时间越来越长，团队能够逐渐消除交流损失。成员们在一起经历很多事情，团队就会变得越来越健壮，甚至能够克服交流的损失。作为一个整体，团队能够比单个个体的简单加和做得更好。度量度量每个产品的规模不要执着于单位 - 在等待客观度量的时候，用你自己的主观单位从所有能得到的原始数据（可计算的软件特性）自己构造度量单位从已经完成得项目中收集原始数据，以推导出生产力趋向借助数据库画一条趋势线，把预期工作量作为人造度量值的函数显示出来现在，针对每个要评估的项目，计算出人造度量单位值，并根据这个值在趋势线上找到预期工作量用生产力趋势周围的干扰水平作为映射的标示改变完成工作的方式如果不大幅度减少调试的时间，就没办法让项目大幅度提前完成高速完成的项目用在调试上的时间也成比例地少得多高速完成的项目用在设计上的时间也成比例地多得多如果你不关心别人，不照顾别人，就别想让他们为你做一些不同寻常的事情。如果要让他们改变，就必须去了解（并赞赏）他们的过去压力的效果压力之下的人无法更快地思考增加加班时间只会降低生产力短期的压力乃至于加班可能是有用的策略，因为他们能使员工集中精力，并且让他们感到工作的重要性。但是长期的压力肯定是错误的。经理之所以会施加那么多的压力，也许是因为他们不知道该做什么，或者因为其他办法的困难而感到气馁。最坏的猜测：使用压力和加班的真正原因是为了在项目失败的时候，让所有人看上去能好点。最法西斯的做法：管理就像是替驴子干活一样，相信压力能极大地提高生产力，也许能让项目完成的时间缩短一半，甚至超过一半。加班会使人在正常工作日中浪费时间。提升工作效率应该是：雇人、激励、团队变动、留住优秀的人、排除掉无用的方法、减少会议、减少加班、减少多余的文档。但是这是一个非常难的操作和道路。如果一堆程序员感觉不到自己的价值（或做事情的价值），他们是不会形成特别紧密的团队的。含糊的规格文档规格文档中的含糊标志着不同的系统参与者之间存在着未解决的冲突如果一份规格文档不包含完整的输入输出列表，那么它就是毫无希望的：它根本就没开始说明任何东西没有人会告诉你一份规格文档是不是糟糕。人们往往倾向于责备自己，而不是责备文档。冲突团队所有人的目标一致的时候，才有可能没有冲突。但是实际上是，团队很复杂，不同的人有不同的目标，这才是合理的组织，这样冲突就可能产生了。冲突应当引起重视。冲突并不是缺乏职业道德的行为。应当提前声明：所有人的“赢”都是受重视的。确保每个级别的人都能赢谈判困难；调解容易如果两个人的利益是完全或者部分相斥的，预先做好安排，准备好请双方通过调解来解决冲突记住：我们都站在同一边，跟我们对立的，是我们要解决的问题。催化剂的角色有这样一种催化剂式的人物，这样的人能够帮助团队成型并凝聚，保持团队的健康和生产力，从而对项目做出贡献。就算“催化剂”别的什么事情都不干（其实，通常他们还会干很多别的事），这种催化剂的角色也是重要而有价值的调解是“催化剂”的一项特殊工作。调解是可以学的，而且只需要很小的投资就能学会调解应该从一个小小的仪式开始。“我能帮你们调解一下吗？” 在解决冲突的时候，这是必要的第一个步骤。人员安排：在早期，人员超编会迫使项目跨过关键的设计阶段（这是为了让所有的人有事可做）如果在设计完成之前，工作先被分给了很多人，那么人与人之间、工作组之间的接口就会很乱套这会是团队内部耦合度提高，会议时间、重复劳动和无效工作都会增加理想的人员安排是这样：在项目的大部分时间里由小型核心团队来做设计工作，在开发的最后阶段（时间安排的最后1/6）加入大量的人手可怕的猜想：时间安排紧迫的项目，与时间安排比较合理的项目比起来，完成的时间反而会更长项目社会学：让不必与会的人可以放心离开，从而保证会议的精简。有一份公开的议程，并严格执行，这是最简单的办法项目需要仪式用小小的仪式来使人们注意项目的目标和理想的状态：小规模会议、零缺陷工作等等采取行动，防止人们随便发怒记住：愤怒=恐惧。随便对下级发怒的经理一定是因为恐惧才会这样做的意见： 如果所有人都懂得“愤怒=恐惧”这个道理，就能明显地看出发怒的人是在害怕。由于无法再隐瞒自己的恐惧，他也就不会再生气了。病态的政治（旧话重提）别想根治一个病态的人不要浪费时间，也不要因为尝试治疗上司的病态而使自己受到威胁有时候，你唯一的选中就是等待，等问题自己解决，或者等一个让你继续前进的机会奇迹时有可能发生的（但是千万别去指望它）精兵简政精兵简政是支败公司使用哦办法，它让员工负担失败的责任公司的目标应该正好相反：兴旺而人性化当你听到“精兵简政”这个词的时候，请记住它的玄外之音：失败和恐吓基本常识：项目既需要目标，也需要计划而且这两者应该不同最后贴一张在MBAlib中看到的 布鲁斯·塔克曼的团队发展阶段模型本文地址： https://leaf0s.fun/2018/03/12/1343718827/]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[大型网站技术架构读书笔记]]></title>
    <url>%2F2017%2F10%2F31%2F2972100119%2F</url>
    <content type="text"><![CDATA[大型网站技术架构读书笔记最近一直在读&lt;大型网站技术架构&gt;这本书, 对里面的观点非常赞同: 任何大型的技术架构都是&quot;长出来的&quot;, 而不是设计出来的.1. 网站架构的基本演变方式网站最初的形态可能在一台服务器上, 后来由于数据量和业务的需要, 逐渐发展成如下架构:应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU；数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘。这个架构的问题是：数据库压力太大导致访问延迟，进而影响整个网站的性能当业务量和数量量级再大一些的时候, 就需要加缓存, 架构演变如下:网站使用的缓存可以分为两种：缓存在应用服务器上的本地缓存和缓存在专门的分布式缓存服务器上的远程缓存。本地缓存的访问速度更快一些，但是受应用服务器缓存限制，其缓存数据量有限，而且会出现和应用程序争内存的情况。远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量验证的缓存服务。通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈。目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。利用这一点实现数据读写分离，从而改善数据库负载压力。使用反向代理和CDN加速网站响应使用分布式文件系统和分布式数据库系统，分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。2. 网站架构所使用的一般技术网站架构模式分层分割分布式方式： 1.分布式应用和服务、2.分布式静态资源、3.分布式数据和存储、4.分布式计算、5.分布式配置、6.分布式锁、7.分布式文件集群：对同一个应用，需要单独不是服务器的集群化缓存方式：1.CDN、2.反向代理、3.本地缓存、4.分布式缓存。缓存是改善软件性能的第一手段。使用缓存有两个前提条件：1.数据访问热点不均衡 2.数据在某段时间内有效，缓存除了可以加快数据访问速度，还可以减轻后端应用和数据存储的负载压力，网站数据库几乎都是按照有缓存的前提进行负载能力设计的。异步：1.在第一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将输出写入队列，后面的线程从队列中读取数据进行处理；2.在分布式系统中，多个服务器集群通过分布式消息队列实现异步，分布式消息队列可以看作内存队列的分布式部署。使用异步方式处理业务可能会对用户体验、业务流程造成影响，需要网站产品设计方面的支持。冗余：访问和负载很小的服务也必须部署至少两台服务器构成一个集群，其目的就是通过冗余实现服务高可用。数据库除了定期备份，存档保存，实现冷备份外，为了保证在线业务高可用，还需要对数据库进行主从分离，实时同步实现热备份。自动化：1.自动化代码管理 2.自动化测试 3.自动化安全检测 4.自动化部署 5.自动化监控 6.自动化监控 7.自动化报警 8.自动化失效转移 9.自动化失效恢复 10.自动化降级 11.自动化分配资源3. 网站架构的非业务要素一般说来，除了当前的系统功能需求外，软件架构还需要关注性能、可用性、伸缩性、扩展性和安全性这5个架构要素，架构设计过程中需要平衡这5个要素之间的关系，以实现需求和架构目标，也可以通过考察这些架构要素来衡量一个软件架构设计的优劣。性能：衡量网站性能有一系列指标，重要的有响应时间，TPS，系统性能计数器等可用性：网站高可用性的主要手段是冗余，应用部署在多台服务器上同时提供访问，数据存储在多台服务器上互相备份，任何一台服务器宕机都不会影响应用的整体可用，也不会导致数据丢失。对于应用服务器而言，多台应用服务器通过负载均衡设备组成一个集群共同对外提供服务，任何一台服务器宕机，只需把请求切换到其他服务器就可实现应用的高可用，但是一个前提条件是应用服务器上不能保存请求的会话信息。否则服务器宕机，会话丢失，即使将用户请求转发到其他服务器上也无法完成业务处理。伸缩性：衡量架构伸缩性的主要标准就是是否可以用多台服务器构建集群，是否容易向集群中添加新的服务器。加入新的服务器后是否可以提供和原来的服务器无差别的服务。集群中可容纳的总的服务器数量是否有限制。对于应用服务器集群，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可以向集群中不断加入服务器。。扩展性：不同于其他架构要素主要关注非功能性需求，网站的扩展性架构直接关注网站的功能性需求。网站快速发展，功能不断扩展，如何设计网站的架构使其能够快速响应需求变化，是网站可扩展架构主要的目的。本文地址： https://leaf0s.fun/2017/10/31/2972100119/]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习关于流量探测相关论文的总结]]></title>
    <url>%2F2017%2F08%2F12%2F417249395%2F</url>
    <content type="text"><![CDATA[机器学习关于流量探测相关论文的总结最近由于工作方面的原因, 一直在看机器学习方面相关的论文, 特别是关于流量探测方法的. 记录一下学习过程中的一些知识点.基于机器学习的网络流量分类网络流量分类方法概览图传统的流量分类主要基于：端口与分组深度解析两种方法。基于数据包深度解析的方法，有2个假设作为应用前提：a) 除数据包源与接收者外的第三方能提取每个IP分组载荷明文 b) 需要分类的每种已知应用的语法和特征。（如果者两点成立，将具有准确率高的特点）机器学习不依赖匹配协议端口或解析协议内容识别网络应用，而是利用流量在传输过程中表现出来的“网络流”（flow）的各种统计特性区别网络应用。网络流的5元组定义：（源IP地址，目的IP地址，源端口，目的端口，协议）有监督的离线训练模型有监督的在线训练模型在线训练框架的基本表述：训练阶段，该框架首先对实时网络流量进行抽样并通过特征提取与样本标记产生训练数据集，然后使用在线学习算法对分类模型进行训练。 特征提取可使用 Ｍoore 提出的 248 维网络流统计特征，样本标记可使用深度包检测工具nDPI以及开源工具 Tstat。 测试阶段，该框架使用训练完成的模型对实时网络流量进行分类。 将模型分类结果与 nDPI与 Tstat等工具的结果对比，当偏差达到一定阈值时对模型进行重新训练。在线训练算法，要求训练速度要快，所以选择的算法都是一些能够快速训练完成，并更新的算法。这类算法一般比SVM，朴素贝叶斯等的准确率要低，但是训练速度快，在离线模式下比较少会用到。算法有：1）一阶算法：感知机算法、OGD算法（在线梯度下降算法）、PA算法（Passive-Aggressive）、PA-I、PA-II 2）二阶算法：CW算法（Confidence-Weighted）、SCW算法（Soft Confidence-weighted）算法。特征选择算法分为：过滤（filter）和封装（wrapper）两种方法。过滤特征选择算法较多：基于相关性的子集搜索方法CFS、基于一致性的子集搜索方法CON、FCBF, SFS等。封装代表算法有基于遗传算法的wrapper方法等。在样本类别未知的情况下，需要选用无监督的特征选择算法，如一钟基友熵的Filter模型（无监督的特征选择算法还比较少）评估方法I 有监督机器学习流量分类K-最邻近（K-nearest neighbor, KNN）,5组特征：分组层次、流层次、连接层次、流域连接内部特征、同一源目主机间的多条并发流的特征。 泛化性太差，计算开销大朴素贝叶斯（Naive bayes, NB）,各个特征独立并遵循高斯分布。实际应用中的原始流量特征很难满足此条件，准确率只有65%。改进：1）使用特征选择方法对特征集合进行过滤，并使用核密度估计来改进 2）使用贝叶斯神经网络。 贝叶斯增广朴素贝叶斯方法（BAN），通过结合主元分析法与K-均值聚类算法，构建一个朴素贝叶斯网络分类算法。 有后验概率的缺点，准确率高，但是不稳定基于C4.5决策树，1）特征选择和boosting增强方法改进 2）利用信息熵来构建分类模型。 3）AdaBoost+C4.5算法构建决策树，利用关联的过滤方法筛选出12个最优特征 4）CVFDF决策树识别P2P流量。分类计算量小，分类准。 局部最优，训练计算量大支持向量机（SVM）1）利用非线性变换和结构风险最小化（structural risk minimization, SRM）原则将流量分类问题转化为二次寻优问题，使用了247个流特征 2）V-SVM作为二值支持向量机识别P2P流量。分类特征取网络连接数相关统计特征，将网络流分为P2P流和non-P2P流两类，受环境影响大。 分类稳定、准确率高，小样本训练空间依然保持较好的分类性能。大样本训练慢，满足不了实时需求（改进SVM应用大样本研究有意义）神经网络 1）基于BP神经网络识别P2P流，采用3层BP神经网络层次结构，判断P2P和non-P2P，根据经验隐藏层取4. 训练速度慢 2）利用概念神经网络（probabilistic neural network， PNN）解决流量分类问题，训练速度快，分类类型数量有限 3）fuzzy ART-MAP神经网络应用P2P流识别。4）极限学习机（ELM），是一种快速的机器学习算法，基于具有任意隐藏节点的单隐藏层前馈神经网络（SLFN），学习速度快，泛化性好，稳定性高。5）AdaBoost算法。 神经网络目前局限于小规模流量数据与较少流量类型应用实时流量分类。1）将网络流量按协议的不同阶段（建立连接、数据传输、结束连接）划分为不同子流，统计分析每条子流的特征向量并构造流量分类模型 2）进一步研究自动提取合适的子流用于训练，采用EM聚类方法对子流进行聚类，提取最能代表应用流特征的子流构造训练集，降低分类模型训练的计算复杂度 3）利用应用协议在早期协商阶段的行为特征对其进行识别。partial decision tree的准确率最高。 比较新的特征尝试，待验证集成学习分类方法。集成学习技术是将多个不同/相同分类模型集成使用的方法，有很强的泛化能力，拥有比单个分类器更好的性能，能提高准确率和稳定性。选择准确率高和差异性大的分类器用于集成学习，能够很好地提高集成后分类器的性能。结合SVM，BAN，BP神经网络3种方法的不同优点，通过对3种分类器实行加权平均组合权重的方式，来进行分类。II 无监督机器学习的流量分类无监督机器学习方法根据流量统计特征的相似性进行聚合分簇，然后建立各个簇与类的映射关系。无监督机器学习具有能够自动发现新应用的特点，但其检测精度与分类速度明显低于有监督的分类方法。EM算法。期望最大化（expectation maximaization， EM）算法，可将具有相同特性（大文件传送、多交互等）的流聚到同一簇。尝试HTTP、FTP、SMTP、IMAP、NTP与DNS六种流量。 需要解决如何建立聚类簇与流应用类型之间的映射关系。通常需要手工标记K-Means算法。1）使用TCP连接的前5个数据分组的大小来代表不同的网络流。严重依赖网络流的分组到达顺序，无法保证分类的稳定性与实用性。2）使用X-Means算法，将每个聚类簇应用类型标注为簇内占大多数的刘的应用类型，利用刘的前32字节的统计特征作为训练输入 3）使用一种两阶段的网络流量分类方法，提取网络流初始建立阶段与平稳阶段的特征来描述网络流，并采用无监督K-Means聚类分两个阶段训练分类器。 由于特征的选取的关系，都不太稳定3.DBSCAN算法。优点：1）只需要少量领域知识即能确定输入参数 2）能形成任意形状的聚类簇 3）适用于大规模数据集。 通用性比较差AutoClass算法。ＥＭ 算法的无监督贝叶斯分类器。 分类效果好，但是计算量大FCM算法（ 模糊C均值聚类）。FCM算法需要两个参数：聚类数目参数C和柔性参数m。C控制聚类的数目，m控制聚类的效果。算法的输出是C个聚类中心点向量和C*N的一个模糊划分矩阵，这个矩阵表示的是每个样本点属于每个类的隶属度。根据这个划分矩阵按照模糊集合中的最大隶属原则就能够确定每个样本点归为哪个类。聚类中心表示的是每个类的平均特征，可以认为是这个类的代表点。 分类效果好，但是不稳定分类效果：AutoClass &gt; FCM &gt; K-Means &gt; DBSCAN分类数量：AutoClass &gt; FCM &gt; K-Means &gt; DBSCANIII 半监督机器学习的流量分类半监督机器学习主要关注当训练数据的部分信息缺失（如数据的类别标签缺失、部分特征维缺失等）的情况下，如何获得具有良好性能和泛化能力的分类器。首先，通过聚类算法将训练集分成不同的簇，然后通过被标记的流实现簇与类别之间的映射，那些不包含任何标记流的簇就被视为未知的新应用类型。再通过这些被标记的簇来训练有监督的学习模型。半监督根据训练数据是否完全标记，分为：归纳式半监督学习和直推式半监督学习半监督学习方法只需利用少量标注样本和大量未标注样本即可实现分类，可以有效减少标注代价，提高机器学习的性能，但它对于有噪声干扰样本数据的分类效果并不理想，而且由于它提出的时间比较短，其应用价值还需要更多的深入研究。利用少量的标记数据辅助K-Means聚类过程，确定簇与流量类型的映射关系。提出一种基于熵函数的组合式特征选择方法，首先计算所有特征的熵，前d个最优特征构成候选的特征子集，其次采用顺序后台搜索方法，以分类器本身的分类准确率为评估标准，借此去除冗余特征。然后在结合监督学习，例如SVM方法进行流量分类。基于GMM（高斯混合模型）的半监督学习来进行网络流的分类（Semi-supervised internet network traffic classification using a Gaussian mixture model）。基于FCM（模糊聚类模型）的半监督入侵检测，通过使用异构距离来计算隶属度改进FCM的聚类算法。先将有标签的数据通过改进的FCM算法计算类中心，再将无标签的数据通过改进的FCM算法加入到对应的类，重新计算类中心。基于粒子群的KNN半监督学习算法。通过粒子群PSO来改进KNN的聚类算法一般准确率高于无监督，低于有监督。属于比较新的研究领域。挑战样本标注瓶颈，因此利用少量的以标注样本和大量的未标注样本训练一个好分类器是为了研究方向（半监督机器学习）样本分布不均衡，无法保证分类器的稳定性。研究发现，SVM对样本分布的健壮性好于NB方法实时与连续分类，现在大多数研究工作都是利用完整流的统计特征，因此分类器只有在接收到完整的IP流后才能进行预测分类，无法满足实时要求。分类算法可扩展性。面对互联网海量的各类网络应用刘，需要对现有机器学习方法进行改进以适应大规模网络流量分类。SVM不适用于大规模数据集训练，时间O(m3)和空间O(m2)复杂度太高。Gartner研究副总裁Tracy Tsai认为，到2020年，将有40 %的安全厂商会声称具备人工智能相关能力。她认为目前人工智能主要应用在如下领域，包括应用程序安全测试，以减少误报；恶意软件检测，用于终端保护；漏洞测试目标选择；SIEM管理；用户和实体行为分析（UEBA）； 网络流量分析等方面。本文地址： https://leaf0s.fun/2017/08/12/417249395/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习(ML)的总结和思考]]></title>
    <url>%2F2017%2F06%2F11%2F3454466964%2F</url>
    <content type="text"><![CDATA[怎么样能知道机器学习在某个项目/环境中的可行的（可行性分析）？目前判断AI技术是否能够实现某个项目，一个简单的思路是：一般人能在几秒钟内想出来的事情，就能够用AI去实现。即：人能够预测、分类或者判断的事物，机器学习在理论上都可以完成。AI进展最快的领域正是人能够做得到的领域。而人类难以做到的事情，AI可能也难做到。原因1：人类能做的，至少是可行的原因2：可以利用人类的数据作为培训样本，比如：有监督的学习原因3：人类能提供指导。通过人类的判断，对机器学习算法/参数进行修正原因4：目前机器学习/AI的水平还是处在模仿人类的初级阶段，并没有到超越人类的阶段。什么是机器学习？两种解释：机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法机器学习就是通过算法，使得机器能从大量历史数据中学习规律，从而对新的样本做智能识别或对未来做预测机器学习的本质是什么？机器学习是统计学、概率论、计算机科学和生物学等相互交叉的综合学科。但是从目前的实用来看，机器学习更偏向于统计学和概率论。因此凡是统计学上的研究方式或方法，基本上是适合机器学习的。统计学中，几百年不变的方法：获取数据—&gt;分析数据—&gt;建立模型—&gt;预测未知，在机器学习中也是如此。机器学习统计学收集数据采样/获取数据找特征分析数据向量化数据化建立模型建立模型/寻找分布函数预测获取分布概率/预测机器学习的三种方式机器学习本质是统计学，统计学的准确度，只和两个变量有关：1. 数据 2. 模型。因此机器学习通常使用以下三种方式：数据量大，但是采用比较简单的模型，而且比较少的迭代次数，也就是说用大量的数据做一个浅层的机器学习。（传统机器学习）数据量小，但是采用比较复杂的模型，而且经过很多次迭代训练出准确的模型参数。（早期机器学习研究方式，统计学习）数据量大，但是使用多个简单的模型（越等于复杂模型），多次迭代，训练出准确的模型。（深度学习）通常，由大量的数据，较少迭代训练出来的“较粗糙”的模型，要比用少量的数据、深度的学习精耕细作得到的模型效果更好。深度学习在数据量足够大的情况下，能够用若干简单的模型取代一个复杂的模型。它是先有大量的数据，而不是预设模型，然后用很多简单的模型去契合数据（Fit Data）。机器学习和大数据目前机器学习的驱动力，是大数据。机器学习的另一个角度是：统计模型+数据 = 人工智能，其思路是变智能问题为数据问题。所以目前机器学习的重点在于如何提取数据中的信息来教会机器进行预测/判断。从信息的角度上看机器学习，机器学习就是把智能问题转化成消除不确定性的问题，然后再找到能够消除相应不确定性的信息，如此而已。机器学习的方法论是信息论。机器学习的数据集和特征根据统计学，机器学习的数据集基本要满足以下两点。测试样本和训练样本独立分布，即样本必须和实际应用场景高度相似，否则不能保证算法的有效性。样本数量必须足够大。当样本的数据只是全集的一部分时，所得到的样本要尽量有代表性（样本的完备性）。训练的数据由两部分构成：正确的训练集和错误的训练集，这两部分训练集最好在数量上相等，并且样本数量足够全，能够覆盖到最多情况。什么是深度神经网络？深度神经网络是一种具备至少一个隐藏层的神经网络。与浅层神经网络类似，深度神经网络也能为复杂非线性系统提供建模，但多出的层次为模型提供了更高的抽象层次，因而提高了模型的能力。深度神经网络通常都是前馈网络，但也有语言建模等方面的研究将其拓展到循环（递归）神经网络。总的来说:深度神经网络通常是前馈型神经网络深度神经网络说的是一种结构，而不是一种算法。所以，我们在谈论机器学习的某种网络的时候，我们在谈论什么？ 谈论的是网络结构。深度学习是神经网络的一个大分支，深度学习的基本结构是深度神经网络。什么是强化学习？强化学习有点像是有监督的学习，只是标注的数据不是预先准备好的，而是通过一个过程来回地调整并给出所谓的“标注数据”。这个过程通常称为回报函数，这个回报函数决定当前状态得到什么样的结果（”好“还是”坏“），其数学本质是一个马尔科夫决策过程。最终的目的是决策过程中整体回报函数期望最优。监督学习的方法监督学习方法分成生成方法（Generative Approach）和判别方法（Discriminative Approach），所学到的模型分别称为生成模型（Generative Model）和判别模型（Discriminative Model）。判别方法：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括：感知机、决策树、支持向量机等生成方法：从数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)，即生成模型P(Y|X)=P(X,Y)/P(X)。典型的生成模型有：朴素贝叶斯模型，隐马尔科夫模型等。生成算法(GAN)尝试找出到底这个数据是怎么生成的（产生的），然后再对一个信号进行分类。基于你的生成假设，那么那个类别最有可能产生这个信号，这个信号就属于那个类别。判别模型不关心数据是怎么生成的，它只关心信号之间的差别，然后用差别简单地对给定的一个信号进行分类。有生成模型可以得到判别模型，但由判别模型得不到生成模型。深度学习和传统机器学习（模式识别）区别除了传统机器学习深度（建模层数）上的差异。传统的机器学习一般人工手动提取数据集中的特征，而深度学习能够自己提取/学习数据集中的特征。深度学习有个别名Unsupervised Feature Learning，Unsupervised意思是深度学习一般在获取数据的特征上是无监督的。准确说，深度学习首先利用无监督学习对每一层进行逐层预训练（Layerwise Pre-Training）去学习特征；每次单独训练一层，并将训练结果作为更高一层的输入；然后到最上层改用监督学习从上到下进行微调（Fine-Tune）去学习模型。使用自下而上的非监督学习（就是从底层开始，一层一层地往顶层训练）。自顶向下的监督学习，就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调。深度学习和降维在深度学习中，隐藏层的特征数（节点数）往往比上一层要少，在机器学习中，这叫做降维。为什么深度学习要降维：由于深度学习的输入数据往往是原始数据（例如：一幅图的像素），给的特征粒度太细了，如果不进行处理，这些特征将毫无意义。抽象，将细粒度的特征组合成有意义的特征。模仿人类的大脑，字组成词，词组成句子，句子组成文章。压缩，将特征的数据量进行压缩，能够更快的进行计算去噪，根据信息论的观点，原始的数据包含了太多信息噪音，不利于信息的获取，需要在使用之前去噪。迁移学习监督学习是一种用已标记数据训练预测算法的技术。监督学习需要大量已标记的训练数据，但是数据有时是非常昂贵的。通常，机器学习算法需要大约5000个已标记的训练样本才能达到一定的效果。但如果要达到人类预测水平的话，则需要至少50,000个已标记样本。监督学习最大的困难，是获取足够大的已标记数据的语料库。如果克服这些数据挑战已成为一个主要的研究领域。而其中的一种解决方案就是迁移学习，一种将解决某一问题时得到的知识应用于其他相关问题的技术。可以首先寻找那些廉价或免费可用的标签数据集来训练算法，然后，使用较小的一个标签数据集训练同一算法以进行预测。迁移学习是运用已有的知识对不同但相关领域问题进行求解的一种新的机器学习方法，迁移学习的目标是将从一个环境中学到的知识用来帮助新环境中的学习任务，迁移已有的知识解决目标领域中仅有少量有标签样本数据甚至没有样本数据的学习问题。两个不同领域相关的方面越多，迁移学习就越容易实现；相关的方面越少，则迁移学习就越困难，甚至可能产生副作用。迁移学习可以从现有的样本数据中迁移只是到相关领域，用来帮助相关领域的学习。利用好迁移学习，可以提高样本数据利用率，提供机器学习效率。深度学习总结深度学习的前身是人工神经网络（artifical neural network, ANN），人工神经网络由各个层组成，输入层（input layer）输入训练数据，在输出层（output layer）输出计算结果，中间有1个或多个隐藏层（hidden layer），使输入数据向前传播到输出层。“深度”一词没有具体的特指，一般就是要求隐藏层很多（一般是指5层，10层，几百层甚至几千层）人工神经网络的每一层由大量的节点（神经元）组成，层与层之间有大量的连接，但是层内部的神经元一般互相独立。深度学习的过程需要神经元具备以下两个特性。1）激活函数（activation function）:这个函数一般是非线性函数，也就是每个神经元通过这个函数将原有的来自其他神经元的输入做一个非线性变化，输出给下一层神经元。激活函数实现的非线性能力是前向传播（forward propagation）很重要的一部分。2）成本函数（cost function）：用来定量评估在特定输入值下，计算出来的输出结果距离这个输入值的真实值有多远，然后不断调整每一层的权重参数，是最后的损失值最小。这就是完成了一次反向传播（backward propagation）。损失值越小，结果就越可靠。神经网络算法的核心就是计算、连接、评估、纠错和训练，而深度学习的深度就在于通过不断增加中间隐藏层数和神经元数量，让神经网络变得又深又宽，让系统运行大量数据，训练它。计算机的学习和人类的学习类似，我们平时大量做题（训练数据），不断地经过阶段性考试（验证数据）的检验，用这些知识和解题方法（模型）最终走向最终（测试数据）的考场。“学习”家族的整体构造图深入学习入门深入学习流行框架: TensorFLow. TensorFLow的一大亮点是支持异构设备分布式计算（heterogeneous distributed computing）在目前的深度学习的研究领域主要有以下3类人群学者。主要做深度学习的理论研究，研究如何设计一个“网络模型”，如何修改参数以及为什么这样修改效果会好。平时的工作主要是关注科研前沿和进行理论研究、模型实验等，对新技术、新理论很敏感。算法改进者。这些人为了把现有的网络模型能够适配自己的应用，达到更好的效果，会对模型做出一些改进，把一些新算法改进应用到现有模型中。这类人主要是做一些基础的应用服务，如基础的语音识别服务、基础的人脸识别服务，为其他上层应用方提供优良的模型。工业研究者。这类人群不会涉及太深的算法，主要掌握各种模型的网络结构和一些算法实现。他们更多地是阅读优秀论文，根据论文去复现成果，然后应用到自己所在的工业领域。这个层次的人也是现在深度学习研究的主流人群。深度学习和机器学习及控制系统之间的区别这一轮人工智能火爆起来就是因为CNN用来处理人脸识别的图象，CNN最早的是模拟猫的眼睛处理图像的视觉相关部分的神经和大脑结构，它是天然的比较适合用来处理图像。时序神经网络RNN，因为交易类场景有下单和成交时序，适合于股票期货交易算法，长短时神经元网络族LSTMfamily，适用于语音识别，科大讯飞的核心语音识别算法就是属于一个变形的LSTM算法。级联随机森林 cascade random forest，适合于决策，最高法和某大型国有科研机构合作的智慧司法项目去年底找到我们外包做人工智能模拟法官判案决策逻辑。量子热力学模拟退火算法，它也不属于深度学习，当我们在超级复杂的系统里面，想计算系统的状态代价函数的全局最小点，这种特别复杂的情况下，有时候用梯度下降算法容易陷在局部最小点跳不出来，就要用这种算法。本文地址： https://leaf0s.fun/2017/06/11/3454466964/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2017%2F03%2F29%2F3405742080%2F</url>
    <content type="text"><![CDATA[库管理克隆库12git clone https://github.com/php/php-src.gitgit clone --depth=1 https://github.com/php/php-src.git # 只抓取最近的一次 commit历史管理查看历史12git log --pretty=oneline filename # 一行显示git show xxxx # 查看某次修改标签功能12345678git tag # 显示所有标签git tag -l 'v1.4.2.*' # 显示 1.4.2 开头标签git tag v1.3 # 简单打标签git tag -a v1.2 9fceb02 # 后期加注标签git tag -a v1.4 -m 'my version 1.4' # 增加标签并注释， -a 为 annotated 缩写git show v1.4 # 看某一标签详情git push origin v1.5 # 分享某个标签git push origin --tags # 分享所有标签回滚操作12git reset 9fceb02 # 保留修改git reset 9fceb02 --hard # 删除之后的修改取消文件的修改12git checkout -- a.php # 取消单个文件git checkout -- # 取消所有文件的修改删除文件12git rm a.php # 直接删除文件git rm --cached a.php # 删除文件暂存状态移动文件1git mv a.php ./test/a.php查看文件修改12git diff # 查看未暂存的文件更新git diff --cached # 查看已暂存文件的更新暂存和恢复当前staging12345git stash # 暂存当前分支的修改git stash apply # 恢复最近一次暂存git stash list # 查看暂存内容git stash apply stash@&#123;2&#125; # 指定恢复某次暂存内容git stash drop stash@&#123;0&#125; # 删除某次暂存内容修改 commit 历史纪录1git rebase -i 0580eab8分支管理创建分支12git branch develop # 只创建分支git checkout -b master develop # 创建并切换到 develop 分支合并分支1234git checkout master # 切换到 master 分支git merge --no-ff develop # 把 develop 合并到 master 分支，no-ff 选项的作用是保留原分支记录git rebase develop # rebase 当前分支到 developgit branch -d develop # 删除 develop 分支克隆远程分支12git branch -r # 显示所有分支，包含远程分支git checkout origin/android修复develop上的合并错误将merge前的commit创建一个分之，保留merge后代码将develop reset –force到merge前，然后push –force在分支中rebase develop将分支push到服务器上重新merge强制更新到远程分支最新版本12git reset --hard origin/mastergit submodule update --remote -fSubmodule使用克隆带submodule的库1git clone --recursive https://github.com/chaconinc/MainProjectclone主库后再去clone submodule123git clone https://github.com/webff/webff.github.ogit submodule initgit submodule updateGit设置Git的全局设置在~/.gitconfig中，单独设置在project/.git/config下.忽略设置全局在~/.gitignore_global中，单独设置在project/.gitignore下.设置 commit 的用户和邮箱12git config user.name "xx"git config user.email "xx@xx.com"或者直接修改config文件123[user]name = xxxemail = xxx@xxx.com查看设置项1git config --list设置git终端颜色123git config --global color.diff autogit config --global color.status autogit config --global color.branch auto本文地址： https://leaf0s.fun/2017/03/29/3405742080/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 Theano]]></title>
    <url>%2F2016%2F12%2F05%2F2494141133%2F</url>
    <content type="text"><![CDATA[安装Theano不太难，但是在安装的时候确实遇到了一些坑，记录一下，免得以后忘记了。（实际上以前装过一次，但是没写下来，这几天又爬了一遍坑）在安装theano之前下列举下，theano的工具依赖：必须：Linux, Mac OS X 和Windows 操作系统。推荐操作系统使用64位的，theano官方开发的系统为64位Linux 系统，其他版本的系统未实际测试。所以安装theano最好使用Linux 64bitPython 2 &gt;=2.6 or Python 3 &gt;= 3.3。系统中需要安装python的开发包（centos 安装 python-devel， ubuntu安装python-dev）。Python2.4仅支持到theano 0.6的版本；Python3 必须大于3.3，才能使用theanog编译器（Linux和Windows平台），clang(macOS平台)。编译器是必须的，除了g外，还应该包含gcc编译器，在有些版本的Linux中gcc不是默认安装的（例如：Centos Mini版本）NumPy&gt;=1.7.1, 小于1.7.1版本的NumPy包可能能够使用，但是theano官方没有经过测试，所以不推荐使用1.7.1之前的版本，最好是使用NumPy最新的版本。推荐使用pip install numpy安装，也可以是yum安装python-numpy。但是pip安装numpy能保证最新版本的更新和获取。SciPy&gt;=0.11，SciPy包对稀疏矩阵和矩阵函数的支持是theano所必须的，推荐使用0.11版本以上的。通过pip install scipy 安装。不要使用scipy0.8版本以下的，因为在0.8版本以下的SciPy包对解析稀疏矩阵存在BUG。BLAS（基础线性代数程序集）库的安装。系统中需要安装BLAS的库，Linux根据版本安装以-dev, -devel结尾的包（yum install blas-devel lapack-devel atlas-devel，centos安装命令），Mac OS X已经自带了，Windows 需要在网上下载二进制安装包。可选：nose&gt;=1.3.0 和nose-parameterized&gt;=0.5.0。运行theano测试用例必须的包，也能跑numpy和scipy的测试用例。推荐使用pip install nose nose-parameterized安装Sphinx&gt;=0.5.1和pygments，构建theano文档必须的库。pip install sphinx pygmentsGit 。获取theano最新代码的工具。graphiz 和 pydot-ng。graphiz使theano能够生成Theano计算图。pydot-ng是graphiz的接口包，是对老版本的pydot包的替代和兼容。安装系统库命令：yum install graphviz graphviz-devel graphviz-doc graphviz-graphs。安装Python 包命令： pip install pydot-ngNVIDIA CUDA 驱动和SDK。这是必须的安装包，对于使用NVIDIA GPU来做theano计算。libgpuarray，libgpuarray是使用CUDA和OpenCL必须要求使用的依赖包。Centos 7 安装 theano1234567sudo yum install python-devel gcc gcc-gfortran gcc-c++ blas-devel lapack-devel atlas-develsudo yum install graphviz graphviz-devel graphviz-doc graphviz-graphssudo pip install pydot-ngsudo pip install nose nose-parameterizedsudo pip install sphinx pygmentssudo pip install numpy scipysudo pip install Theano测试Theano，NumPy和SciPy是否安装成功NumPy测试，耗时30s：python -c &quot;import numpy; numpy.test()&quot;SciPy测试，耗时1m：python -c &quot;import scipy; scipy.test()&quot;Theano测试，耗时30m：python -c &quot;import theano; theano.test()&quot;Theano的测试通常非常慢，推荐使用Theano/BLAS方法来测试Theano，BLAS是非常快的线性代数库，比NumPy和SciPy快了大概10倍。测试命令例如：1python /usr/lib/python2.*/site-packages/theano/misc/check_blas.py问题安装theano完成后，在python 代码中，敲入：import theano，包括上面测试的时候，报错如下：网上查询+分析后，定位原因在于：Python 在编译的时候，libpython2.7.a库中的abstract.o模块的编译过程中，没有加上-fPIC；如果是系统自带的Python，一般是缺失这个参数的。解决方法网上说，是重新编译一套带fPIC参数的Python。但是我不想替换掉系统的Python，于是就想能不能，在一台虚拟机上编译带fPIC参数的Python，编译好了以后，将生成的libpython2.7.a去替换掉目的机器的libpython2.7.a。编译Python的脚步命令：123456cd /tmpwget https://www.python.org/ftp/python/2.7.12/Python-2.7.12.tar.xztar xf Python-2.7.12.tar.xzcd Python-2.7.12./configure --prefix=/usr/local/ --enable-shared CFLAGS=-fPICmake &amp;&amp; make installps： 编译需要gcc和gcc-c++，必须保证编译的系统中安装了这两个编译器安装后的Python库在/usr/local/lib下，如图：libpython2.7.so.1.0就是我们要找的库拷贝出 libpython2.7.so.1.0，放到目标机器中的相应目录，从报错中可以找到该目录，上面报错中说的目录是/opt/workplace/pyenv/versions/2.7.12/lib。123mv ./libpython2.7.a ./libpython2.7.a.bakchmod 555 libpython2.7.so.1.0ln -s libpython2.7.so.1.0 libpython2.7.a再运行python， 执行import theano。没有报错了，说明替换成功了，解决了该问题。ps：自己编译出来的libpython2.7.a比系统提供的要小很多，不知道有没有什么影响，待观察。实际使用了一些Python库，都没有问题。本文地址： https://leaf0s.fun/2016/12/05/2494141133/]]></content>
      <categories>
        <category>技术实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议读书笔记]]></title>
    <url>%2F2015%2F12%2F09%2F3418525752%2F</url>
    <content type="text"><![CDATA[HTTP协议读书笔记通读了一遍&quot;图解HTTP协议&quot;这本书, 确实对HTTP协议有了进一步的认识和理解. 读书笔记如下:WWW构建技术：1）把SGML作为页面的文本标记语言HTML2）作为文档传递协议的HTTP3）指定文档所在地址的URL请求报文：请求报文是由请求方法、请求URI、协议版本、可选的请求首部字段和内容实体构成的。响应报文：响应报文基本上由协议版本、状态码（表示请求成功或失败的数字代码）、用以解释状态码的原因短语、可选的响应首部字段以及实体主体构成。HTTP报文本身是由多行（用CR+LF作换行符）数据构成的字符串文本。HTTP报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR+LF）来划分。通常，并不一定要有报文主体。请求报文和响应报文的首部内容由以下数据组成。请求行：包含用于请求的方法，请求URI和HTTP版本状态行：包含表明响应结果的状态码，原因短语和HTTP版本首部字段：包含表示请求和响应的各种条件和属性的各类首部。一般有4种首部，分别是：通用首部、请求首部、响应首部和实体首部其他：可能包含HTTP的RFC里未定义的首部（Cookie等）使用首部字段是为了给浏览器和服务器提供报文主体大小、所使用的语言、认证信息等内容。HTTP首部字段是由首部字段名和字段值构成的，中间用冒号&quot;:&quot;分隔。首部字段名: 字段值另外，字段值对应单个HTTP首部字段可以有多个值。HTTP首部字段根据实际用途被分为以下4种类型。通用首部字段（General Header Fields）请求报文和响应报文两方都会使用的首部。请求首部字段（Request Header Fields）从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。响应首部字段（Response Header Fields）从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。4.实体首部字段（Entity Header Fields）针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。HTTP首部字段根据缓存代理和非缓存代理的行为，分成2种类型:端到端首部（End-to-end Header）逐跳首部（Hop-by-hop Header）HTTP方法GET:获取资源POST:传输实体主体PUT:传输文件HEAD:获得报文首部DELETE:删除文件OPTIONS:询问支持的方法TRACE:追踪路径CONNECT:要求用隧道协议连接代理状态码的职责是当客户端向服务器端发送请求时，描述返回的请求结果。200 OK 表示从客户端发来的请求在服务器端被正常处理了204 No Content 表示服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分206 Partial Content 表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求301 Moved Permanently 永久性重定向。302 Found 临时性重定向303 See Other 请求对应的资源存在着另一个URI，应使用GET方法定向获取请求的资源304 Not Modified 表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。使用缓存，没有任何的响应主体部分。307 Temporary Redirect 临时重定向。该状态码与302 Found有着相同的含义。307会遵照浏览器标准，不会从POST变成GET。400 Bad Request 表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发生请求。401 Unauthorized 表示发送的请求需要有通过HTTP认证（BASIC认证、DIGEST认证）的认证信息。403 Forbidden 表明对请求资源的访问被服务器拒绝了404 Not Found 表明服务器上无法找到请求的资源。（拒绝请求且不想说明理由时使用）500 Internal Server Error 表明服务器端在执行请求是发生了错误。也可能是Web应用存在的bug或某些临时的故障。503 Service Unavailable 表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入Retry-After首部字段再返回给客户端。HTTP通信时，除了客户端和服务器以外，还有一些用于通信数据转发的应用程序，例如：代理、网关和隧道。代理是一种有转发功能的应用程序，他扮演了位于服务器和客户端“中间人”的角色，接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端。（每次通过代理服务器转发请求或响应时，会追加写入Via首部信息）网关是转发其他服务器通信数据的服务器，接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理。有时客户端可能都不会察觉，自己的同学目标是一个网关。（利用网关可以由HTTP请求转化为其他协议通信）3.隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方同学来南京的应用程序。（隧道可按要求建立起一条鱼其他服务器的通信线路，届时使用SSL等加密手段进行通信。）HTTP + 加密 + 认证 + 完整性保护 = HTTPS通常HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。即，所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP。HTTP标准中的瓶颈：一条连接上只可发送一个请求。请求只能从客户端开始。客户端不可以接受除响应以外的指令。请求/响应首部未经压缩就发生。首部信息越多延迟越大。发送冗长的首部。每次互相发送相同的首部造成的浪费较多。可任意选择数据压缩格式。非强制压缩发送。请求异步解决方案:Ajax解决方案Ajax（Asynchronous JavaScript and XML，异步JavaScript与XML技术）是一种有效利用JavaScript和DOM（Document Object Model，文档对象模型）的操作，以达到局部Web页面替换加载的异步通信手段。Ajax的核心技术是名为XMLHttpRequest的API，通过JavaScript脚本语言的调用就能和服务器进行HTTP通信。而利用Ajax实时地从服务器获取内容，有可能会导致大量请求产生。另外,Ajax仍未解决HTTP协议本身存在的问题。Comet的解决方法一旦服务器端有内容更新了，Comet不会让请求等待，而是直接给客户端返回响应。这是一种通过延迟应答，模拟实现服务器端向客户端推送（Server Push）的功能。通常，服务器端接收到请求，在处理完毕后就会立即返回响应，但为了实现推送功能，Comet会先将响应置于挂起状态，当服务器端有内容更新时，再返回该响应。因此，服务器端一旦有更新，就可以立即反馈给客户端。内容上虽然可以做到实时更新，但为了保留响应，一次连接的持续时间也变长了。期间，为了维持连接会消耗更多的资源。另外，Comet也仍未解决HTTP协议本身存在的问题。SPDY协议SPDY没有完全改写HTTP协议，而是在TCP/IP的应用层与传输层之间通过新加会话层的形式运作。同时，考虑到安全性问题，SPDY规定通信中使用SSL。使用SPDY后，HTTP协议额外获得以下功能多路复用流赋予请求优先级压缩HTTP首部推送功能服务器提示功能SPDY基本上只是将单个域名（IP地址）的通信多路复用，所以当一个Web网站上使用多个域名下的资源，改善效果就会受到限制。WebSocket使用浏览器进行全双工通信当时筹划将WebSocket作为HTML5标准的一部分，而现在他却逐渐变成独立的协议标准。WebSocket即Web浏览器与Web服务器之间全双工通信标准。WebSocket技术主要是为了解决Ajax和Comet里XMLHTTPRequest附带的缺陷所引起的问题。由于是建立在HTTP基础上的协议，因此连接的发起方仍是客户端，而一旦确立WebSocket通信连接，不论服务器还是客户端，任意一方都可直接向对方发送报文。WebSocket协议的主要特点：1.推送功能2.减少通信量HTTP/2.0 7项技术本文地址： https://leaf0s.fun/2015/12/09/3418525752/]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[javascript核心基础学习总结]]></title>
    <url>%2F2015%2F11%2F24%2F2664142027%2F</url>
    <content type="text"><![CDATA[javascript核心基础学习一个完整的JavaScript实现由下列三个不同的部分组成核心（ECMAScript）文档对象模型（DOM）浏览器对象模型（BOM）ECMA-262定义的ECMAScript与Web浏览器没有依赖关系，ECMA-262定义的只是这门语言的基础，它规定了这门语言的下列组成部分：语法 2. 类型 3. 语句 4. 关键字 5. 保留字 6. 操作符 7. 对象第3版标志着ECMAScript成为了一门真正的编程语言。IE9中提供了对ECMA-262第5版的完整支持。文档对象模型（DOM， Document Object Model）是针对XML但经过扩展用于HTML的应用程序编程接口（API）。DOM把整个页面映射为一个多层节点结构。DOM并不只是针对JavaScript的，很多别的语言也都实现了DOM。DOM1级由两个模块组成：DOM核心（DOM Core）和DOM HTMLDOM2级引入了下列新模块：DOM视图（DOM Views）DOM事件（DOM Events）DOM样式（DOM Style）DOM遍历和范围（DOM Traversal and Range）DOM3级对DOM做了进一步扩展：1.DOM加载和保存（DOM Load and Save）2.DOM验证模块 （DOM Validation）BOM 浏览器对象模型，开发人员使用BOM可以控制浏览器显示的页面以外的部分。关键字和保留字ECMA-262描述了一组具有特定用途的关键字，这些关键字可用于表示控制语句的开始或结束，或者用于执行特定操作等。按照规则，关键字也是语言保留的，不能用作标识符。ECMA-262还描述了另外一组不能用于用作标识符的保留字。尽管保留字在这门语言中还没有任何特定的用途，但是它们有可能在将来被用作关键字。ECMAScript中有5种简单数据类型（也称为基本数据类型）: Undefined、Null、Boolean、Number和String。还有1种复杂数据类型----Object，Object本周上是由一组无序的名值对组成的。ECMAScript不支持任何创建自定义类型的机制，而所有值最终都将是上述6种数据类型之一。永远不要测试某个特性的浮点数值。与其他语言不同，ECMAScript没有为整数和浮点数值分别定义不同的数据类型，Number类型可用于表示所有数值。Object类型是所有它的实例的基础。Object类型所具有的任何属性和方法也同样存在于更具体的对象中。语句do-while是种后测试循环语句，最常用于循环体中的代码至少要被执行一次的情形。while语句属于前测试循环语句，也就是说，在循环提内的代码被执行前，就会对出口条件求值。因此，循环体内的代码可能永远不会被执行。for语句也是一种前测试循环语句，但它具有在执行之前初始化变量和定义循环后要执行的代码的能力。如果表示要迭代的对象的变量值为null或undefined，for-in语句会抛出错误。ECMAScript5更正了这一行为：对这种情况不再抛出错误，而只是不执行循环体。为了保证最大限度的兼容性，建议在使用for-in循环之前，先检测确认该对象的值不是null或undefined。函数return语句可以不带有任何返回值。在这种情况下，函数在停止执行后将返回undefined值。这种用法一般用在需要提前停止函数执行而又不需要返回值的情况下。实际上，在函数体内可以通过arguments对象来访问这个参数数组，从而获取传递给函数的每一个参数。如果变量是给定引用类型（根据它的原型链来识别）的实例，那么instanceof操作符就会返回true每个执行环境都有一个与之关联的变量对象（variable object），环境中定义的所有变量和函数都保存在这个对象中。使用var声明的变量会自动被添加到最接近的环境中。在函数内部，最接近的环境就是函数的局部环境；在with语句中，最接近的环境是函数环境。如果初始化变量时没有使用var声明，该变量会自动被添加到全局环境。变量的执行环境有助于确定应该何时释放内存。JavaScript具有自动垃圾收集机制，也就是说，执行环境会负责管理代码执行过程中使用的内存。这种垃圾收集机制的原理其实很简单：找出那些不再继续使用的变量，然后释放其占用的内存。为此，垃圾收集器会按照固定的时间间隔（或代码执行中预定的收集时间），周期性的执行这一操作。内存限制问题不仅会影响给变量分配内存，同时还会影响调用栈以及在一个线程中能够通知执行的语句数量。引用类型有时也被称为对象定义，因为它们描述的是一类对象所具有的属性和方法。对象是某个特定引用类型的实例。新对象是使用new操作符后跟一个构造函数来创建的。构造函数本身就是一个函数，只不过该函数是出于创建新对象的目的而定义的。ECMAScript提供了很多原生引用类型。创建Object实例的方式有两种。第一种是使用new操作符后跟Object构造函数。另一种方式是使用对象字面量表示发。对象字面量是对象定义的一种简写形式，目的在于简化创建包含大量属性的对象的过程。最好的做法是对那些必需值使用命令参数，而是要对象字面量来封装多个可选参数。引用类型与基本包装类型的主要区别就是对象的生存期。使用new操作符创建的引用类型的实例，在执行流离开当前作用域之前都一直保存在内存中。而自动创建的基本包装类型的对象，则只存在于一行代码的执行瞬间，然后立即被销毁。ECMA-262把对象定义为：”无序属性的集合，其属性可以包含基本值，对象或者函数“，我们可以把ECMAScript的对象想象成散列表：无非就是一组名值对，其中值可以是数据或函数。每个对象都是基于一个引用类型创建的，也可以是开发人员定义的类型。可以通过Object.defineProperty 和 Object.defineProperties来详细创建JavaScript中的对象属性。使用Object.getOwnPropertyDescriptor方法来读取一个对象的属性设置。在JavaScript中，可以针对任何对象–包括DOM和BOM对象，使用Object.getOwnPropertyDescriptor()方法。Object.getOwnPropertyDescriptor()方法只能用于实例属性，要取得原型属性的描述符，必须直接在原型对象上调用Object.getOwnPropertyDescriptor()方法。任何函数，只要通过new操作符来调用，那它就可以作为构造函数；而任何函数，如果不通过new操作符来调用，那它跟普通函数也不会有什么两样。无论什么时候，只要创建了一个新函数，就会根据一组特定的规则为该函数创建一个prototype 属性，这个属性指向函数的原型对象。在默认情况下，所有原型对象都会自动获得一个constructor （构造函数）属性，这个属性包含一个指向prototype 属性所在函数的指针。就拿前面的例子来说，Person.prototype.constructor 指向Person。而通过这个构造函数，我们还可继续为原型对象 添加其他属性和方法。创建了自定义的构造函数之后，其原型对象默认只会取得constructor 属性；至于其他方法，则 都是从Object 继承而来的。当调用构造函数创建一个新实例后，该实例的内部将包含一个指针（内部 属性），指向构造函数的原型对象。ECMA-262 第5 版中管这个指针叫[[Prototype]]。虽然在脚本中 没有标准的方式访问[[Prototype]]，但Firefox、Safari 和Chrome 在每个对象上都支持一个属性 proto；而在其他实现中，这个属性对脚本则是完全不可见的。不过，要明确的真正重要的一点就 是，这个连接存在于实例与构造函数的原型对象之间，而不是存在于实例与构造函数之间。ECMAScript 5 增加了一个新方法，叫Object.getPrototypeOf(),在所有支持的实现中，这个方法返回[[Prototype]]的值。每当代码读取某个对象的某个属性时，都会执行一次搜索，目标是具有给定名字的属性。搜索首先从对象实例本身开始。如果在实例中找到了具有给的名字的属性，则返回该属性的值；如果没有找到，则继续搜索指针指向的原型对象，在原型对象中查找具有给定名字的属性。如果在原型对象中找到了这个属性，则返回该属性的值。这正是多个对象实例共享原型所保存的属性和方法的基本原理。虽然可以通过对象实例访问保存在原型中的值，但却不能通过对象实例重写原型中的值。如果我们在实例中添加了一个属性，而该属性与实例原型中的一个属性同名，那我们就在实例中创建该属性，改属性将会屏蔽原型中的那个属性。要取得对象上所有可枚举的实例属性，可以使用ECMAScript5的object.keys()方法。这个方法接收一个对象作为参数，返回一个包含所有可枚举属性的字符串数组。如果要得到所有实例属性，无论它是否可枚举。都可以使用Object.getOwnPropertyNames()方法。创建自定义类型的最常见方式，就是组合使用构造函数模式与原型模式。构造函数模式用于定义实例属性，而原型模式用于定义方法和共享的属性。结果，每个实例都会有自己的一份实例属性的副本，但同时又共享着对方法的引用，最大限度地节省了内存。另外，这种混成模式还支持向构造函数传递参数；可谓是集两种模式之长。构造函数在不返回值的情况下，默认会返回新对象实例。而通过在构造函数的末尾添加一个return语句，可以重写调用构造函数时返回的值。许多OO语言都支持两种继承方式：接口继承和实现继承。在ECMAScript中无法实现接口继承。ECMAScript只支持实现继承，而且其实现继承主要是依靠原型链来实现的。实现原型链有一种基本模式, 其代码大致如下:123456789101112131415161718192021function SuperType() &#123; this.property = true&#125;SuperType.prototype.getSuperValue = function() &#123; return this.property;&#125;;function SubType() &#123; this.subproperty = false&#125;//继承了 SuperTypeSubType.prototype = new SuperType();SubType.prototype.getSubValue = function() &#123; return this.subproperty;&#125;;var instance = new SubType()alert(instance.getSuperValue()); //ture一句话，SubType继承了SuperType，而SuperType继承了Object。当调用instance.toString()时，实际上调用的是保存在Object.prototype中的那个方法。本文地址： https://leaf0s.fun/2015/11/24/2664142027/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[openstack学习总结]]></title>
    <url>%2F2015%2F05%2F28%2F174279324%2F</url>
    <content type="text"><![CDATA[openstack学习总结OpenStack由以下5部分构成的：Nova-计算服务Swift-存储服务Glance-镜像服务Keystone-认证服务Horizon -UI服务Keystone、Dashboard二者与其它OpenStack部分的交互Nova——OpenStack计算设施：Nova是OpenStack计算的弹性控制器。OpenStack云实例生命期所需的各种动作都将由Nova进行处理和支撑，这就意味着Nova一管理平台的身份登场，负责管理整个云的计算资源、网络、授权及测度。虽然Nova本身并不提供任何虚拟能力，但是它将使用libvirt API与虚拟机的宿主机进行交互。Nova通过Web服务API来对外提供处理接口，而且这些接口与Amazon的Web服务接口是兼容的。功能及特点实例生命周期管理计算资源管理网络与授权管理基于REST的API异步连续通信支持各种宿主：Xen、XenServer/XCP、KVM、UML、VMware vSphere及Hyper-VNova弹性云包含以下主要部分：API Server(nova-api)消息队列（rabbit-mq server）运算工作站（nova-compute）网络控制器（nova-network）卷管理（nova-volume）调度器（nova-scheduler）Glance——OpenStack镜像服务器OpenStack镜像服务器是一套虚拟机镜像发现、注册、检索系统，我们可以将镜像存储到以下任意一种存储中：本地文件系统OpenStack对象存储S3直接存储S3对象存储（作为S3访问的中间渠道）HTTP（只读）功能及特点提供镜像相关服务Glance构件Glance控制器Glance注册器Swift——OpenStack存储设施Swift为OpenStack提供一种分布式、持续虚拟对象存储，它类似于Amazon Web Service的S3简单存储服务。Swift具有跨节点百级对象的存储能力。Swift内建冗余和失效备援管理，也能够处理归档和媒体流，特别是对大数据（千兆字节）和大容量（多对象数据）的测度非常高效。功能及特点海量对象存储大文件（对象）存储数据冗余管理归档能——处理大数据集为虚拟机和云应用提供数据容器处理流媒体对象安全存储备份与归档良好的可伸缩性Swift组件Swift帐户Swift容器Swfit对象Swift代理Swift RINGKeystone——OpenStack认证服务Keystone为所有的OpenStack组件提供认证和访问策略服务，它依赖自身REST（基于Identity API）系统进行工作，主要对（但不限于）Swift、Glance、Nova等进行认证与授权。事实上，授权通过对动作消息来源者请求的合法性进行鉴定。Keystone采用两种授权方式，一种基于用户名/密码，另一种基于令牌（Token）。除此之外，Keystone提供以下三种服务：令牌服务：含有授权用户的授权信息目录服务：含有用户合法操作的可用服务列表策略服务：利用Keystone具体指定用户或群组某些访问权限Horizon——OpenStack管理的Web接口Horizon是一个用以管理、控制OpenStack服务的Web控制面板，他可以管理实例、镜像、创建密钥对，对实例添加卷、操作Swift容器等。除此之外，用户还可以在控制面板中使用终端（console）或VNC直接访问实例。。总之，Horizon具有如下特点：实例股哪里：创建、终止实例，查看终端日志，VNC连接，添加卷等访问与安全管理：创建安全群组，管理密钥对，设置浮动IP等偏好设定：对虚拟硬件模板可以进行不同偏好设定镜像管理：编辑或删除镜像查看服务目录管理用户、配额及项目用途用户管理：创建用户等卷管理：创建卷和快照对象存储处理：创建、删除容器和对象为项目下载环境变量本文地址： https://leaf0s.fun/2015/05/28/174279324/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker命令学习]]></title>
    <url>%2F2015%2F04%2F26%2F1737205767%2F</url>
    <content type="text"><![CDATA[后台启动docker服务1sudo docker -d &amp;下载一个ubuntu镜像1sudo docker pull ubuntu查看下载的所有docker镜像1sudo docker images （显示精简镜像ID，带参数-notrunc=true，显示完整镜像ID）查看某个镜像的详细信息1sudo docker inspect 精简ID显示镜像的层次结构1sudo docker images -tree通过指定文件（Dockerfile）来创建一个新的容器12sudo docker build -t vieux/apache:2.0sudo docker build github.com/creack/docker-firefox提交一个容器12sudo docker ps -lsudo docker commit c3f279d17e0a SvenDowideit/testimage:version3将容器的文件和目录复制到主机中12sudo docker cp 7bb0e258aefe:/etc/debian_version .sudo docker cp blue_frog:/etc/hosts .列出更改的容器文件系统文件和目录1sudo docker diff 7bb0e258aefe从服务器获取实时事件信息1sudo docker events（监听事件）导出容器系统作为一个tar文档发送到stdout1sudo docker export red_panda &gt; latest.tar12.创建一个空容器系统镜像和引用压缩文件的内容12sudo docker import http://example.com/exampleimage.tgzcat exampleimage.tgz | sudo docker import - exampleimagelocal:new （引用本地文件）显示镜像的历史操作1sudo docker history docker显示整个容器系统信息1sudo docker info通过url给镜像容器增加文件12sudo docker insert 8283e18b24bc https://raw.github.com/metalivedev/django/master/postinstall /tmp/postinstall.sh06fd35556d7b查看容器底层信息12sudo docker inspect 60734sudo docker inspect -format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' $INSTANCE_ID（获取一个容器ip地址）杀死一个正在运行的容器（发送终止信号）1Usage: docker kill CONTAINER [CONTAINER...]从输入流中加载一个压缩包，恢复包含的所有镜像和tag1Usage: docker load &lt; ubuntu.tar登陆你在docker服务器注册的账号 index.docker.io12Usage: docker login [OPTIONS] [SERVER]docker login localhost:808020.取出容器的log日志1Usage: docker logs [OPTIONS] CONTAINER查找私有地址转换到共有地址端口1Usage: docker port [OPTIONS] CONTAINER PRIVATE_PORT查看正在运行的镜像12Usage: docker ps [OPTIONS]-a=false: 查看所有的镜像 默认情况下只查看正在运行的镜像从远程仓库中获取镜像1Usage: docker pull NAME推送本地镜像到远程仓库1Usage: docker push NAME重启正在运行的远程仓库1Usage: docker restart [OPTIONS] NAME删除一个或者所有的容器1Usage: docker rm [OPTIONS] CONTAINER删除一个或者多个镜像123Usage: docker rmi IMAGE [IMAGE...]sudo docker rmi fd484f19954fsudo docker rmi test2run1234567891011121314151617181920212223242526272829Usage: docker run [OPTIONS] IMAGE[:TAG] [COMMAND] [ARG...]Run a command in a new container -a=map[]: 附加标准输入、输出或者错误输出 -c=0: 共享CPU格式（相对重要） -cidfile="": 将容器的ID标识写入文件 -d=false: 分离模式，在后台运行容器，并且打印出容器ID -e=[]: 设置环境变量 -h="": 容器的主机名称 -i=false: 保持输入流开放即使没有附加输入流 -privileged=false: 给容器扩展的权限 -m="": 内存限制 (格式: &lt;number&gt;&lt;optional unit&gt;, unit单位 = b, k, m or g) -n=true: 允许镜像使用网络 -p=[]: 匹配镜像内的网络端口号 -rm=false:当容器退出时自动删除容器 (不能跟 -d一起使用) -t=false: 分配一个伪造的终端输入 -u="": 用户名或者ID -dns=[]: 自定义容器的DNS服务器 -v=[]: 创建一个挂载绑定：[host-dir]:[container-dir]:[rw|ro]. 如果容器目录丢失，docker会创建一个新的卷 -volumes-from="": 挂载容器所有的卷 -entrypoint="": 覆盖镜像设置默认的入口点 -w="": 工作目录内的容器 -lxc-conf=[]: 添加自定义 -lxc-conf="lxc.cgroup.cpuset.cpus = 0,1" -sig-proxy=true: 代理接收所有进程信号 (even in non-tty mode) -expose=[]: 让你主机没有开放的端口 -link="": 连接到另一个容器 (name:alias) -name="": 分配容器的名称，如果没有指定就会随机生成一个 -P=false: Publish all exposed ports to the host interfaces 公布所有显示的端口主机接口docker会先创建一个新的可写的容器层来指定镜像，通过指定命令来启动他, docker run相当于运行API/containers/create在/container/(id)/start之前docker run命令可以用结合docker commit来改变正在运行的容器！通过标准输出流存储镜像包含所有父层的、tag、version1Usage: docker save image &gt; repository.tar搜索docker 镜像1Usage: docker search TERM启动一个停止的容器1Usage: docker start [OPTIONS] CONTAINER关闭一个容器1Usage: docker stop [OPTIONS] CONTAINER [CONTAINER...]给镜像仓库添加标签1Usage: docker tag [OPTIONS] IMAGE REPOSITORY[:TAG]查看容器内运行的进程1Usage: docker top CONTAINER [ps OPTIONS]显示docker的版本和最后更新版本信息1sudo docker version等待容器停止，打印出退出编码1Usage: docker wait [OPTIONS] NAME本文地址： https://leaf0s.fun/2015/04/26/1737205767/]]></content>
      <categories>
        <category>技术总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu12.04 下安装Docker]]></title>
    <url>%2F2015%2F04%2F24%2F2100280121%2F</url>
    <content type="text"><![CDATA[ubuntu12.04 下安装Docker检测Linux内核版本通过 uname -a 命令查看当前系统linux内核版本，如果版本低于3.8，需要升级linux的内核（docker在linux的kernel3.8上运行最佳，ubuntu12.04内置的内核一般是3.2版本）安装内核12sudo apt-get updatesudo apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raring重启1sudo reboot检测apt系统的https兼容性，如果不是最新版或者/usr/lib/apt/methods/https文件不存在，请安装apt-transport-https包，因为这是获取docker安装文件的重要步骤1sudo apt-get install apt-transport-https添加docker库的密钥1sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9添加docker库的源12sudo bash -c "echo deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list"sudo apt-get update安装docker1sudo apt-get install lxc-docker后台运行服务的命令是sodu docker -d &amp;,在最新版的docker，已经不需要再额外执行，安装好之后，docker的服务会自动启动。安装成功后，下载ubuntu镜像并启动镜像来验证安装是否正常（会需要点时间）1sudo docker run -i -t ubuntu /bin/bash如果请求超时, 请更换docker的镜像源, 最好是换成国内的, 例如: 阿里的. 后面会说到怎么替换镜像源成功运行后，退出容器环境1exit安装遇到的问题：docker 和 ufw（如果你安装了ufw，并启动了它）Dockers是用桥接的方式管理容器的网络，默认情况下，如果你安装了UFW防火墙，他会过滤掉所有的转发，所以你需要允许UFW转发123456sudo nano /etc/default/ufw----# Change:# DEFAULT_FORWARD_POLICY="DROP"# toDEFAULT_FORWARD_POLICY="ACCEPT"然后刷新UFW1sudo ufw reload当然你也可以只放行Docker容器允许的端口42431sudo ufw allow 4243/tcpdocker和网络延迟ping get.docker.io,看下延迟。如果访问不了或者访问延迟很高，可以在网上搜索docker的镜像网站，来替代get.docker.io。例如使用Yandex的镜像来替代get.docker.io,Yandex是一个俄罗斯的镜像站点，每6小时更新一次用http://mirror.yandex.ru/mirrors/docker/ 替代 http://get.docker.io/ubuntu1234sudo sh -c "echo deb http://mirror.yandex.ru/mirrors/docker/ docker main\&gt; /etc/apt/sources.list.d/docker.list"sudo apt-get updatesudo apt-get install lxc-dockerRed Hat Enterprise Linux安装docker教程顺便简单说下redhat怎么装docker注意事项是redhat是社区贡献的所以这个不需要我多说了，人家建议用ubuntu安装步骤如下:1234567891011121314#安装包sudo yum -y install docker-io#升级安装包sudo yum -y update docker-io#启动dockersudo service docker start#开机启动，加入3,5就可以了sudo chkconfig docker on#然后运行吧--比较坑的就是fedorasudo docker run -i -t fedora /bin/bash本文地址： https://leaf0s.fun/2015/04/24/2100280121/]]></content>
      <categories>
        <category>技术实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[虚拟与现实，关于世界的本质]]></title>
    <url>%2F2014%2F05%2F21%2F56693297%2F</url>
    <content type="text"><![CDATA[虚拟与现实，关于世界的本质最近看了一部不错的科幻电影——《异次元骇客》，这部电影的整体设想是围绕着计算机世界中的虚拟现实展开的。故事大致是主人公 为了解开一起谋杀案的谜 团， 在虚拟 和现实中来回穿梭，最后发现了更为惊人的事实。虽然本部影片是一部软科幻作品，但其中还是包含了许多值得人思考的东西。什么是虚拟，什么是现实，世界的本质又是什么？关于计算机模拟现实的科幻电影和小说多不胜数，其中最出名的要数《骇客帝国》。骇客帝国中主角现实的世界和计算机虚拟的世界是两个不同的世界，虚拟世界完全由计算机——超级电脑来进行控制，生活在虚拟中的人大部分都不知道自己是计算机模拟虚构出来的。对于虚拟世界的人来说，他们所生活的即是现实。也就是说，以不同的角度来看，虚拟和现实只不过是一位二体，它们之间的界限是很模糊的。在《 异次元骇客》中，虚拟世界所在的电脑是放在大楼的13层的。通过13这个数字，导演想告诉我们一些信息，就是当一个“人”开始掌握虚拟和现实之间的差异，并意识到自己是“虚拟”的时候，也是他背叛了“神”的时候。根据这种虚拟即是现实的假设来看待我们的世界或者宇宙的时候，是一件非常有趣的事情。霍金曾经说过，物理学的终极目标是发现世界的本质，即一个万能的方程式来解释一切。物理学的本质是找到世界的规律，但世界的规律是怎么来的，那个万能的方程式是谁设置的？我假设所谓的宇宙只不过是一个运行在超级电脑中的程序，宇宙的万物都是这个程序01排列的一部分。我们之所以会思考，会行动都是程序设定好的，一些看似偶然的也许是必然，一切都是根据这个程序中核心的算法——万能方程式在运行。进一步联想一些其他事情，比如：宇宙真的是无限大的吗？——会不会是程序设置的边界保护机制；奇点的状态是什么？——会不会是程序的初始值；为什么会有时间的概念——会不会是一种内存回收机制等等。如果世界的本质真的是一个类似程序的东西，那么它一定是运行在一个超乎我们能够理解的计算机系统（集群？数据中心？超级互联网？）之上的，会不会是超级”云“。并且这个程序应该有时也产生BUG，毕竟是没有完美的程序，而我们会不会就是BUG的产物。但思想或者说灵魂真的能被模拟出来嘛？信息论假说认为，世界的第四维到处分布着信息，任何东西都是信息的载体，信息主导论了我们的世界和思想，我们的所产生的一切情感和思维都是信息释放的产物。如果是真的，那么一切就能够用01表示，包括我们自己的肉体和灵魂。计算机是一种信息的表现载体，信息可以说是计算机的灵魂，就好比DNA构造了我们，其实重要的是DNA中包含构造我们的信息。也许有一天，可以将所有人的信息都存储到计算机中去，包括构造我们身体的信息和思想的信息。这样人就会在计算机内重生，生活在计算机内，那里的世界也许和我们这里的世界没什么区别，可能还会好的多——也许人类能够摆脱内存的回收”生老病死“。直到今天为止，我们还并不能理解虚拟和现实之间界限是如何区分的，这个世界的&quot;神&quot;是否真实的存在。也许只有等到我们制造出一个虚拟现实的世界的时候，我们才会开始理解这些。我相信像 《异次元骇客》中这样世界一定会被我们创造出来的，也许是下一代量子计算机，也许是下N代云计算“虚拟和现实，世界的本质”本身就是一个很哲学的问题 ，它其实就蕴涵了”我是谁，我从哪里来，我要到哪里去“。用计算机的话说：就是我是一个被Create的”对象“，来自一个内存单元，最终会被系统回收，释放掉占据的内存，而关于”我“本身的意义，要去问编写”我“这个变量的程序员了，”我”只不过执行了他的命令，是他赋予了“我”初值，给了“我”思想。人类一思考上帝就发笑，我既是“我”也不是“我”， 最后附上一篇写的很好的 《异次元骇客》影评。影评：无论《异次元骇客》，还是《环形废墟》，当其中的角色发现自己只不过是一个幻影时，都表现得十分惶恐、不安、困惑……让我们想象那一刻，如果换了是我们自己，我们又会有什么样的反应呢？在另一部更为有名的“骇客”电影——《 骇客帝国 》中，酷哥 基努李维斯 也生活在虚拟现实之中，这是由一个超级计算机系统所控制的虚幻世界，而真正的“现实”则是战争后的一片废墟。当他经过奇妙的旅程，最终睁开眼睛，那位气度不凡的黑人抵抗领袖带着讥讽的微笑说：“欢迎来到现实的废墟”。生活是一场幻影，现实是一片废墟，这的确是可怕的梦魇。村上春树 的小说《 世界尽头与冷酷仙境 》也为我们提供了类似的梦魇。冷酷仙境是主人公生活的现实世界，而所谓的世界尽头则存在于主人公的潜意识之中。当主人公在现实世界中遭遇种种厄运，满身伤痕，最后意识也即将消失，进入永远黑暗的潜意识世界中时，世界尽头中的他却正在努力从虚幻世界重返现实。如同一缕孤魂徘徊于现实与虚幻之间的他将会作出什么选择，又能作出什么选择呢？真真假假的转换，虚虚实实的混淆，已经成为好莱坞电影的常用情节配备，当我们被那些奇诡的故事壮观的场面所吸引时，很容易忘记这些情节背后所隐藏的对于人类自身存在的追问与思考。这种思考当然是由来以久的，让我们把时间上溯到十七世纪的一个寒冷冬日，怕冷的法国哲学家 笛卡儿 像往常一样，躲到暖和的壁炉里去思考他的那些哲学问题。切莫小觑这看似寻常的一天，后来一位大主教认为，这一天是 欧洲历史 上最倒霉的一天。那么，笛卡儿老兄在壁炉里思考了些什么呢？笛卡儿想到，我们的现实生活可能只是一场梦境，因为我们在做梦时，并不知道在梦中见到的一切是虚假的，只是醒来后才了解到这不过是梦。那么，我们怎么能确定，我们所感受到的真实的一切，不过是另外一场梦呢？笛卡儿还假设，有一个无比强大的恶魔（比如一个超级计算机系统？），出于邪恶的目的，制造了我们周围的一切一切，包括人类的全部历史，我们的全部记忆……笛卡儿对这种种可能进行了周密的思考，众所周知，他的结论是：我思故我在（I think therefore I am.）——只有思考本身才是确定无疑的，由此我们可以确定自身的存在。笛卡儿式的怀疑并不缺少后继者，比如 休谟 认为，除了知觉以外，一切都是不可知的，人只能停留在感觉经验的此岸，无法到达能产生感觉经验的彼岸。就是说，人无法把握世界的本质，感觉经验就象一道屏障，把意识的对象隔离开来，人们永远无法知道这道屏障后面是什么。 康德 把世界分成两个部分：现象界与本体界。人的认识只能局限于现象界，对于本体界，人们则一无所知。从“骇客”扯到 康德 ，我想我已经离题太远了，如何反驳不可知论是哲学家们的事情，我们可以不去管它，还是让我们回到自己的“现实”中来吧。好在我们的现实既不是一片废墟，也不象村上春树笔下的冷酷仙境那么诡异，虽然恐怖事件阴影笼罩，战争烽烟此起彼伏，大部分人仍然可以安居乐业，享受人生。既然我们不可能离开我们所在的现实（或者虚幻），那么又何必去多想呢，就让我们看着《骇客帝国》式的大片，读着村上春树的畅销小说，为了生计来往奔波，感叹汽车房子看来很遥远，太美的女孩总是高不可攀。所以，别问我是谁，别问我来自何方去向何处，因为这个问题永远不会有答案。也许正如一位哲人所说，面对不可言说之事，我们只有保持沉默。本文地址： https://leaf0s.fun/2014/05/21/56693297/]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
</search>
